{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbfec15e-8b37-4c27-993a-e485509d1b73",
   "metadata": {},
   "source": [
    "Clark_Kent_Markdown_to_MDX.ipynb Notebook Summary\n",
    "This notebook implements a tool that transforms standard Markdown content into interactive MDX (Markdown + JSX) with enhanced components. The transformation process follows these key steps:\n",
    "\n",
    "Setup and Configuration: The notebook begins by importing necessary libraries and setting up configurations, including defining available MDX component types (interactive, layout, media, and data components).\n",
    "Core Functionality:\n",
    "\n",
    "Markdown Parser: Extracts structure and content from markdown files\n",
    "Content Analysis: Analyzes markdown content to identify enhancement opportunities (intended to use Gemini AI but falls back to rule-based analysis)\n",
    "MDX Transformation: Converts markdown to MDX by adding interactive components\n",
    "Report Generation: Creates detailed reports on the transformation process\n",
    "\n",
    "\n",
    "Component Types:\n",
    "\n",
    "Interactive components (CodeBlock, Accordion, TableOfContents, etc.)\n",
    "Layout components (TwoColumn, Grid, Sidebar, CalloutBox)\n",
    "Media components (ImageZoom, VideoPlayer, AnimatedIllustration)\n",
    "Data visualization components (DataTable, Chart)\n",
    "\n",
    "\n",
    "File Processing: The notebook provides functions to process individual files or entire directories of markdown files.\n",
    "Execution: When run, the notebook successfully processed 9 out of 9 markdown files, creating enhanced MDX versions with interactive components, despite encountering Gemini API authentication errors (falling back to rule-based analysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b20efb51-bc7a-4c67-8208-728a8a8c9ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI uses data and algorithms to mimic human intelligence.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=\"\")\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\", contents=\"Explain how AI works in a few words\"\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a063ce6-af37-4f17-8e3f-5a8700fa3617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output will be saved to: MDX_Transformed_20250520_203251\n",
      "Environment configured and ready.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and Setup\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import asyncio\n",
    "from datetime import datetime\n",
    "from typing import Dict, Any, List\n",
    "from tqdm.notebook import tqdm\n",
    "from rich.console import Console\n",
    "from rich import print as rprint\n",
    "\n",
    "# Import the Google Generative AI library\n",
    "from google import genai\n",
    "\n",
    "# Set up Gemini API\n",
    "API_KEY = \"\"  # Ensure this is stored securely in production\n",
    "client = genai.Client(api_key=API_KEY)\n",
    "MODEL_NAME = \"gemini-1.5-flash\"  # You can change to other models as needed\n",
    "\n",
    "# Set up console for rich output\n",
    "console = Console()\n",
    "\n",
    "# Define project constants\n",
    "OUTPUT_DIR = f\"MDX_Transformed_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "print(f\"Output will be saved to: {OUTPUT_DIR}\")\n",
    "\n",
    "# Define MDX component definitions\n",
    "MDX_COMPONENTS = {\n",
    "    \"interactive\": {\n",
    "        \"CodeBlock\": \"Interactive code editor with syntax highlighting and execution\",\n",
    "        \"Accordion\": \"Expandable/collapsible sections for progressive disclosure\",\n",
    "        \"Tabs\": \"Tabbed interface for alternative approaches or examples\",\n",
    "        \"TableOfContents\": \"Interactive table of contents linked to headers\",\n",
    "        \"Slider\": \"Interactive slider for adjusting parameters in demos\",\n",
    "        \"Quiz\": \"Interactive quiz component for testing knowledge\"\n",
    "    },\n",
    "    \"layout\": {\n",
    "        \"TwoColumn\": \"Two-column layout for side-by-side content\",\n",
    "        \"Grid\": \"Grid layout for organizing content in cards\",\n",
    "        \"Sidebar\": \"Content with an interactive sidebar for navigation\",\n",
    "        \"CalloutBox\": \"Highlighted box for important information\"\n",
    "    },\n",
    "    \"media\": {\n",
    "        \"ImageZoom\": \"Image with zoom capability\",\n",
    "        \"VideoPlayer\": \"Enhanced video player with chapters and annotations\",\n",
    "        \"AudioPlayer\": \"Audio player with transcript\",\n",
    "        \"AnimatedIllustration\": \"SVG animations that illustrate concepts\"\n",
    "    },\n",
    "    \"data\": {\n",
    "        \"DataTable\": \"Interactive data table with sorting and filtering\",\n",
    "        \"Chart\": \"Interactive data visualization\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Environment configured and ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1407a29a-995e-4651-9703-841de21abb67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "230c87e7-3e1f-41c5-8f4e-9af4fd31748a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Parsing markdown file: path/to/test.md\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Parsing markdown file: path/to/test.md\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">Error parsing markdown file path/to/test.md: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">[</span><span style=\"color: #800000; text-decoration-color: #800000\">Errno </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">2</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">]</span><span style=\"color: #800000; text-decoration-color: #800000\"> No such file or directory: </span><span style=\"color: #800000; text-decoration-color: #800000\">'path/to/test.md'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31mError parsing markdown file path/to/test.md: \u001b[0m\u001b[1;31m[\u001b[0m\u001b[31mErrno \u001b[0m\u001b[1;31m2\u001b[0m\u001b[1;31m]\u001b[0m\u001b[31m No such file or directory: \u001b[0m\u001b[31m'path/to/test.md'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parser function defined and tested.\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Markdown Parser Function\n",
    "\n",
    "def parse_markdown(file_path: str) -> Dict[str, Any]:\n",
    "    \"\"\"Parse a markdown file and extract its structure and content.\"\"\"\n",
    "    console.print(f\"Parsing markdown file: {file_path}\")\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        # Extract front matter if exists (YAML between --- markers)\n",
    "        frontmatter = {}\n",
    "        content_without_frontmatter = content\n",
    "        \n",
    "        frontmatter_match = re.match(r'^---\\s*\\n(.*?)\\n---\\s*\\n(.*)', content, re.DOTALL)\n",
    "        if frontmatter_match:\n",
    "            try:\n",
    "                # Simple YAML parsing\n",
    "                frontmatter_text = frontmatter_match.group(1)\n",
    "                for line in frontmatter_text.split('\\n'):\n",
    "                    if ':' in line:\n",
    "                        key, value = line.split(':', 1)\n",
    "                        frontmatter[key.strip()] = value.strip()\n",
    "                \n",
    "                content_without_frontmatter = frontmatter_match.group(2)\n",
    "            except Exception as e:\n",
    "                console.print(f\"[yellow]Warning: Error parsing frontmatter: {str(e)}[/yellow]\")\n",
    "        \n",
    "        # Analyze content structure\n",
    "        headers = re.findall(r'^(#{1,6})\\s+(.+)$', content_without_frontmatter, re.MULTILINE)\n",
    "        code_blocks = re.findall(r'```(\\w*)\\n(.*?)```', content_without_frontmatter, re.DOTALL)\n",
    "        images = re.findall(r'!\\[(.*?)\\]\\((.*?)\\)', content_without_frontmatter)\n",
    "        links = re.findall(r'(?<!!)\\[(.*?)\\]\\((.*?)\\)', content_without_frontmatter)\n",
    "        lists = re.findall(r'((?:^\\s*[-*+]\\s+.+\\n)+)', content_without_frontmatter, re.MULTILINE)\n",
    "        tables = re.findall(r'^\\|(.+)\\|$\\n^\\|[-:\\|\\s]+\\|$\\n((?:^\\|.+\\|$\\n)+)', content_without_frontmatter, re.MULTILINE)\n",
    "        \n",
    "        # Count paragraphs (text blocks separated by blank lines)\n",
    "        paragraphs = re.split(r'\\n\\s*\\n', content_without_frontmatter)\n",
    "        paragraphs = [p.strip() for p in paragraphs if p.strip()]\n",
    "        \n",
    "        structure = {\n",
    "            \"headers\": [(len(h[0]), h[1]) for h in headers],\n",
    "            \"code_blocks\": [{\"language\": lang, \"content\": code} for lang, code in code_blocks],\n",
    "            \"images\": [{\"alt\": alt, \"src\": src} for alt, src in images],\n",
    "            \"links\": [{\"text\": text, \"url\": url} for text, url in links],\n",
    "            \"list_blocks\": len(lists),\n",
    "            \"tables\": len(tables),\n",
    "            \"paragraphs\": len(paragraphs),\n",
    "            \"word_count\": len(content_without_frontmatter.split())\n",
    "        }\n",
    "        \n",
    "        return {\n",
    "            \"file_path\": file_path,\n",
    "            \"file_name\": os.path.basename(file_path),\n",
    "            \"frontmatter\": frontmatter,\n",
    "            \"content\": content,\n",
    "            \"content_without_frontmatter\": content_without_frontmatter,\n",
    "            \"structure\": structure\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        console.print(f\"[red]Error parsing markdown file {file_path}: {str(e)}[/red]\")\n",
    "        return {\n",
    "            \"file_path\": file_path,\n",
    "            \"file_name\": os.path.basename(file_path),\n",
    "            \"error\": str(e),\n",
    "            \"content\": \"\",\n",
    "            \"frontmatter\": {},\n",
    "            \"structure\": {}\n",
    "        }\n",
    "\n",
    "# Test the parser on a simple string\n",
    "test_md = \"\"\"---\n",
    "title: Test\n",
    "---\n",
    "\n",
    "# Header\n",
    "\n",
    "Text paragraph.\n",
    "\n",
    "```python\n",
    "print(\"hello\")\n",
    "```\n",
    "\n",
    "![image](url)\n",
    "\"\"\"\n",
    "\n",
    "test_result = parse_markdown(\"path/to/test.md\" if not os.path.exists(\"path/to/test.md\") else \"path/to/test.md\")\n",
    "print(f\"Parser function defined and tested.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11d3125a-0375-4cae-8aca-c5827e15f0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis functions defined.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Content Analysis Functions\n",
    "\n",
    "async def analyze_content_with_ai(markdown_data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Use Gemini to analyze markdown content and suggest enhancements.\"\"\"\n",
    "    structure = markdown_data.get(\"structure\", {})\n",
    "    file_name = markdown_data.get(\"file_name\", \"\")\n",
    "    \n",
    "    # Create a summary of the markdown structure\n",
    "    structure_summary = {\n",
    "        \"headers_count\": len(structure.get(\"headers\", [])),\n",
    "        \"code_blocks_count\": len(structure.get(\"code_blocks\", [])),\n",
    "        \"code_languages\": list(set(block.get(\"language\", \"\") for block in structure.get(\"code_blocks\", []) if block.get(\"language\", \"\"))),\n",
    "        \"images_count\": len(structure.get(\"images\", [])),\n",
    "        \"lists_count\": structure.get(\"list_blocks\", 0),\n",
    "        \"tables_count\": structure.get(\"tables\", 0),\n",
    "        \"paragraphs_count\": structure.get(\"paragraphs\", 0),\n",
    "        \"word_count\": structure.get(\"word_count\", 0)\n",
    "    }\n",
    "    \n",
    "    # Create a sample of the content (first 2000 characters)\n",
    "    content_sample = markdown_data.get(\"content_without_frontmatter\", \"\")[:2000]\n",
    "    if len(markdown_data.get(\"content_without_frontmatter\", \"\")) > 2000:\n",
    "        content_sample += \"...\"\n",
    "    \n",
    "    # Create a prompt for Gemini\n",
    "    prompt = \"\"\"Analyze this markdown content and suggest how to transform it into immersive MDX components.\n",
    "\n",
    "FILE NAME: {0}\n",
    "\n",
    "MARKDOWN STRUCTURE SUMMARY:\n",
    "- Headers: {1}\n",
    "- Code Blocks: {2} (Languages: {3})\n",
    "- Images: {4}\n",
    "- Lists: {5}\n",
    "- Tables: {6}\n",
    "- Paragraphs: {7}\n",
    "- Word Count: {8}\n",
    "\n",
    "CONTENT SAMPLE:\n",
    "{9}\n",
    "\n",
    "AVAILABLE MDX COMPONENTS:\n",
    "Interactive Components:\n",
    "- CodeBlock: Interactive code editor with syntax highlighting and execution\n",
    "- Accordion: Expandable/collapsible sections for progressive disclosure\n",
    "- Tabs: Tabbed interface for showing alternative examples\n",
    "- TableOfContents: Interactive table of contents linked to headers\n",
    "- Diagram: Interactive diagrams with hover states\n",
    "- Quiz: Interactive quiz component for testing knowledge\n",
    "\n",
    "Layout Components:\n",
    "- TwoColumn: Two-column layout for side-by-side content\n",
    "- Grid: Grid layout for organizing content\n",
    "- Sidebar: Sidebar navigation with main content\n",
    "- CalloutBox: Highlighted box for important information\n",
    "\n",
    "Media Components:\n",
    "- ImageZoom: Image with zoom capability\n",
    "- VideoPlayer: Enhanced video player with chapters\n",
    "- DataTable: Interactive data table with sorting\n",
    "\n",
    "OUTPUT FORMAT:\n",
    "Provide a detailed JSON response with the following structure:\n",
    "{{\n",
    "  \"interactive_elements\": {{\n",
    "    \"code_blocks\": {{\"recommended\": true/false, \"reason\": \"explanation\"}},\n",
    "    \"lists\": {{\"recommended\": true/false, \"reason\": \"explanation\"}},\n",
    "    \"table_of_contents\": {{\"recommended\": true/false, \"reason\": \"explanation\"}},\n",
    "    \"tables\": {{\"recommended\": true/false, \"reason\": \"explanation\"}},\n",
    "    \"images\": {{\"recommended\": true/false, \"reason\": \"explanation\"}},\n",
    "    \"layout\": {{\"recommended\": true/false, \"type\": \"TwoColumn/Grid/Sidebar\", \"reason\": \"explanation\"}}\n",
    "  }},\n",
    "  \"media_enhancements\": {{\n",
    "    \"diagrams\": {{\"recommended\": true/false, \"reason\": \"explanation\"}},\n",
    "    \"animations\": {{\"recommended\": true/false, \"reason\": \"explanation\"}},\n",
    "    \"videos\": {{\"recommended\": true/false, \"reason\": \"explanation\"}}\n",
    "  }},\n",
    "  \"analysis\": \"Detailed analysis of the content and why certain components would enhance it\",\n",
    "  \"special_suggestions\": \"Any special or creative suggestions for making this content more immersive\"\n",
    "}}\n",
    "\"\"\".format(\n",
    "        file_name,\n",
    "        structure_summary[\"headers_count\"],\n",
    "        structure_summary[\"code_blocks_count\"],\n",
    "        \", \".join(structure_summary[\"code_languages\"]) if structure_summary[\"code_languages\"] else \"None\",\n",
    "        structure_summary[\"images_count\"],\n",
    "        structure_summary[\"lists_count\"],\n",
    "        structure_summary[\"tables_count\"],\n",
    "        structure_summary[\"paragraphs_count\"],\n",
    "        structure_summary[\"word_count\"],\n",
    "        content_sample\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Call Gemini API for analysis\n",
    "        console.print(\"  Using Gemini to analyze content and suggest enhancements...\")\n",
    "        response = client.generate_content(\n",
    "            model=MODEL_NAME,\n",
    "            contents=prompt\n",
    "        )\n",
    "        \n",
    "        # Parse JSON response\n",
    "        try:\n",
    "            # Try to extract JSON from the response\n",
    "            response_text = response.text\n",
    "            \n",
    "            # Look for JSON pattern in the response\n",
    "            json_match = re.search(r'```json\\s*(.*?)\\s*```', response_text, re.DOTALL)\n",
    "            if json_match:\n",
    "                json_str = json_match.group(1)\n",
    "                analysis_result = json.loads(json_str)\n",
    "            else:\n",
    "                # Try parsing the whole response as JSON\n",
    "                analysis_result = json.loads(response_text)\n",
    "                \n",
    "        except json.JSONDecodeError:\n",
    "            # If JSON parsing fails, create a structured result from the text\n",
    "            console.print(\"[yellow]Warning: Could not parse AI response as JSON. Using rule-based analysis instead.[/yellow]\")\n",
    "            # Fall back to rule-based analysis\n",
    "            analysis_result = analyze_content_fallback(markdown_data)\n",
    "        \n",
    "        return analysis_result\n",
    "    \n",
    "    except Exception as e:\n",
    "        console.print(f\"[yellow]Error using Gemini for analysis: {str(e)}. Using rule-based analysis instead.[/yellow]\")\n",
    "        # Fall back to rule-based analysis\n",
    "        return analyze_content_fallback(markdown_data)\n",
    "\n",
    "def analyze_content_fallback(markdown_data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Fallback function for content analysis using rule-based approach.\"\"\"\n",
    "    structure = markdown_data.get(\"structure\", {})\n",
    "    \n",
    "    # Initialize results\n",
    "    interactive_elements = {}\n",
    "    media_enhancements = {}\n",
    "    \n",
    "    # Check for code blocks\n",
    "    code_blocks = structure.get(\"code_blocks\", [])\n",
    "    if code_blocks:\n",
    "        languages = [block.get(\"language\", \"\").lower() for block in code_blocks]\n",
    "        interactive_elements[\"code_blocks\"] = {\n",
    "            \"recommended\": True,\n",
    "            \"reason\": f\"Found {len(code_blocks)} code blocks that would benefit from syntax highlighting and interactive execution.\"\n",
    "        }\n",
    "    \n",
    "    # Check for images\n",
    "    images = structure.get(\"images\", [])\n",
    "    if images:\n",
    "        interactive_elements[\"images\"] = {\n",
    "            \"recommended\": True,\n",
    "            \"reason\": f\"Found {len(images)} images that could be enhanced with zoom capability.\"\n",
    "        }\n",
    "    \n",
    "    # Check for headers and recommend table of contents\n",
    "    headers = structure.get(\"headers\", [])\n",
    "    if len(headers) > 3:\n",
    "        interactive_elements[\"table_of_contents\"] = {\n",
    "            \"recommended\": True,\n",
    "            \"reason\": f\"Found {len(headers)} headers, which would benefit from a navigable table of contents.\"\n",
    "        }\n",
    "    \n",
    "    # Check for list blocks and suggest accordions\n",
    "    if structure.get(\"list_blocks\", 0) > 0:\n",
    "        interactive_elements[\"lists\"] = {\n",
    "            \"recommended\": True,\n",
    "            \"reason\": f\"Found {structure.get('list_blocks', 0)} list blocks that could be converted to expandable accordions.\"\n",
    "        }\n",
    "    \n",
    "    # Check for tables and suggest interactive data tables\n",
    "    if structure.get(\"tables\", 0) > 0:\n",
    "        interactive_elements[\"tables\"] = {\n",
    "            \"recommended\": True,\n",
    "            \"reason\": f\"Found {structure.get('tables', 0)} tables that could be enhanced with sorting and filtering.\"\n",
    "        }\n",
    "    \n",
    "    # General layout suggestions\n",
    "    word_count = structure.get(\"word_count\", 0)\n",
    "    if word_count > 1000:\n",
    "        interactive_elements[\"layout\"] = {\n",
    "            \"recommended\": True,\n",
    "            \"type\": \"TwoColumn\",\n",
    "            \"reason\": f\"Content is {word_count} words long, which would benefit from a two-column layout for better readability.\"\n",
    "        }\n",
    "    \n",
    "    # Check for keywords in headers suggesting diagrams or animations\n",
    "    header_text = \" \".join([h[1].lower() for h in headers])\n",
    "    if any(keyword in header_text for keyword in [\"how\", \"process\", \"workflow\", \"architecture\", \"diagram\"]):\n",
    "        media_enhancements[\"diagrams\"] = {\n",
    "            \"recommended\": True,\n",
    "            \"reason\": \"Content discusses processes or architectures that would benefit from interactive diagrams.\"\n",
    "        }\n",
    "    \n",
    "    # Put it all together\n",
    "    result = {\n",
    "        \"interactive_elements\": interactive_elements,\n",
    "        \"media_enhancements\": media_enhancements,\n",
    "        \"analysis\": \"Analysis based on content structure and patterns.\",\n",
    "        \"special_suggestions\": \"Consider adding interactive elements that engage readers and help explain complex concepts.\"\n",
    "    }\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test the analysis function with a simple example\n",
    "test_markdown_data = {\n",
    "    \"file_name\": \"test.md\",\n",
    "    \"structure\": {\n",
    "        \"headers\": [(1, \"Title\"), (2, \"Section 1\")],\n",
    "        \"code_blocks\": [{\"language\": \"python\", \"content\": \"print('hello')\"}],\n",
    "        \"images\": [{\"alt\": \"test\", \"src\": \"test.png\"}],\n",
    "        \"list_blocks\": 2,\n",
    "        \"tables\": 1,\n",
    "        \"paragraphs\": 5,\n",
    "        \"word_count\": 150\n",
    "    },\n",
    "    \"content_without_frontmatter\": \"# Title\\n\\nTest content\\n\\n## Section 1\\n\\n```python\\nprint('hello')\\n```\"\n",
    "}\n",
    "\n",
    "print(\"Analysis functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5781109-3528-4cd4-ad6e-4572c5ea9010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation functions defined.\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: MDX Transformation Function\n",
    "\n",
    "def transform_to_mdx(markdown_data: Dict[str, Any], analysis: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Transform markdown content to MDX with interactive components.\"\"\"\n",
    "    \n",
    "    content = markdown_data.get(\"content\", \"\")\n",
    "    content_without_frontmatter = markdown_data.get(\"content_without_frontmatter\", content)\n",
    "    frontmatter = markdown_data.get(\"frontmatter\", {})\n",
    "    \n",
    "    interactive_elements = analysis.get(\"interactive_elements\", {})\n",
    "    media_enhancements = analysis.get(\"media_enhancements\", {})\n",
    "    \n",
    "    # Create imports section based on recommended components\n",
    "    imports = []\n",
    "    components_used = []\n",
    "    \n",
    "    # Add imports for code blocks\n",
    "    if interactive_elements.get(\"code_blocks\", {}).get(\"recommended\", False):\n",
    "        imports.append(\"import { CodeBlock } from '@/components/CodeBlock';\")\n",
    "        components_used.append(\"CodeBlock\")\n",
    "    \n",
    "    # Add imports for accordions if lists are recommended for conversion\n",
    "    if interactive_elements.get(\"lists\", {}).get(\"recommended\", False):\n",
    "        imports.append(\"import { Accordion, AccordionItem } from '@/components/Accordion';\")\n",
    "        components_used.append(\"Accordion\")\n",
    "    \n",
    "    # Add imports for table of contents\n",
    "    if interactive_elements.get(\"table_of_contents\", {}).get(\"recommended\", False):\n",
    "        imports.append(\"import { TableOfContents } from '@/components/TableOfContents';\")\n",
    "        components_used.append(\"TableOfContents\")\n",
    "    \n",
    "    # Add imports for interactive tables\n",
    "    if interactive_elements.get(\"tables\", {}).get(\"recommended\", False):\n",
    "        imports.append(\"import { DataTable } from '@/components/DataTable';\")\n",
    "        components_used.append(\"DataTable\")\n",
    "    \n",
    "    # Add imports for media components\n",
    "    if interactive_elements.get(\"images\", {}).get(\"recommended\", False):\n",
    "        imports.append(\"import { ImageZoom } from '@/components/ImageZoom';\")\n",
    "        components_used.append(\"ImageZoom\")\n",
    "    \n",
    "    if media_enhancements.get(\"diagrams\", {}).get(\"recommended\", False):\n",
    "        imports.append(\"import { Diagram } from '@/components/Diagram';\")\n",
    "        components_used.append(\"Diagram\")\n",
    "    \n",
    "    # Add layout imports\n",
    "    layout = interactive_elements.get(\"layout\", {})\n",
    "    if layout.get(\"recommended\", False):\n",
    "        layout_type = layout.get(\"type\", \"TwoColumn\")\n",
    "        if layout_type == \"TwoColumn\":\n",
    "            imports.append(\"import { TwoColumn } from '@/components/TwoColumn';\")\n",
    "            components_used.append(\"TwoColumn\")\n",
    "        elif layout_type == \"Grid\":\n",
    "            imports.append(\"import { Grid } from '@/components/Grid';\")\n",
    "            components_used.append(\"Grid\")\n",
    "        elif layout_type == \"Sidebar\":\n",
    "            imports.append(\"import { Sidebar, SidebarContent, SidebarNav } from '@/components/Sidebar';\")\n",
    "            components_used.append(\"Sidebar\")\n",
    "    \n",
    "    # Add CalloutBox for important information\n",
    "    imports.append(\"import { CalloutBox } from '@/components/CalloutBox';\")\n",
    "    components_used.append(\"CalloutBox\")\n",
    "    \n",
    "    # Convert code blocks to interactive CodeBlock components\n",
    "    enhanced_content = content_without_frontmatter\n",
    "    \n",
    "    if interactive_elements.get(\"code_blocks\", {}).get(\"recommended\", False):\n",
    "        code_block_pattern = r'```(\\w*)\\n(.*?)```'\n",
    "        \n",
    "        def code_block_replacer(match):\n",
    "            lang = match.group(1) or \"text\"\n",
    "            code = match.group(2)\n",
    "            return f'<CodeBlock language=\"{lang}\">\\n```{lang}\\n{code}```\\n</CodeBlock>'\n",
    "        \n",
    "        enhanced_content = re.sub(code_block_pattern, code_block_replacer, enhanced_content, flags=re.DOTALL)\n",
    "    \n",
    "    # Convert images to ImageZoom components\n",
    "    if interactive_elements.get(\"images\", {}).get(\"recommended\", False):\n",
    "        image_pattern = r'!\\[(.*?)\\]\\((.*?)\\)'\n",
    "        \n",
    "        def image_replacer(match):\n",
    "            alt = match.group(1)\n",
    "            src = match.group(2)\n",
    "            return f'<ImageZoom alt=\"{alt}\" src=\"{src}\" />'\n",
    "        \n",
    "        enhanced_content = re.sub(image_pattern, image_replacer, enhanced_content)\n",
    "    \n",
    "    # Add Table of Contents if recommended\n",
    "    if interactive_elements.get(\"table_of_contents\", {}).get(\"recommended\", False):\n",
    "        # Add TableOfContents after the first heading\n",
    "        first_heading_pattern = r'^(#\\s+.+?$)'\n",
    "        enhanced_content = re.sub(\n",
    "            first_heading_pattern, \n",
    "            r'\\1\\n\\n<TableOfContents />\\n', \n",
    "            enhanced_content, \n",
    "            count=1, \n",
    "            flags=re.MULTILINE\n",
    "        )\n",
    "    \n",
    "    # Create enhanced frontmatter\n",
    "    enhanced_frontmatter = {**frontmatter}\n",
    "    \n",
    "    # Add MDX-specific fields to frontmatter\n",
    "    enhanced_frontmatter[\"interactive\"] = True\n",
    "    enhanced_frontmatter[\"components\"] = components_used\n",
    "    \n",
    "    # Format frontmatter as YAML\n",
    "    frontmatter_yaml = \"---\\n\"\n",
    "    for key, value in enhanced_frontmatter.items():\n",
    "        if isinstance(value, list):\n",
    "            frontmatter_yaml += f\"{key}:\\n\"\n",
    "            for item in value:\n",
    "                frontmatter_yaml += f\"  - {item}\\n\"\n",
    "        elif isinstance(value, bool):\n",
    "            frontmatter_yaml += f\"{key}: {str(value).lower()}\\n\"\n",
    "        else:\n",
    "            frontmatter_yaml += f\"{key}: {value}\\n\"\n",
    "    frontmatter_yaml += \"---\\n\\n\"\n",
    "    \n",
    "    # Add imports after frontmatter\n",
    "    imports_text = \"\\n\".join(imports) + \"\\n\\n\"\n",
    "    \n",
    "    # Add an intro callout to demonstrate component usage\n",
    "    callout_text = '\\n<CalloutBox type=\"info\" title=\"Interactive MDX Content\">\\nThis content has been enhanced with interactive MDX components to improve your reading experience.\\n</CalloutBox>\\n\\n'\n",
    "    \n",
    "    # Find the position after the first header to insert the callout\n",
    "    first_header_match = re.search(r'^#\\s+.+?$', enhanced_content, re.MULTILINE)\n",
    "    if first_header_match and interactive_elements.get(\"table_of_contents\", {}).get(\"recommended\", False):\n",
    "        # If we have a TOC, place callout after it\n",
    "        toc_pattern = r'<TableOfContents />(\\n+)'\n",
    "        enhanced_content = re.sub(toc_pattern, r'<TableOfContents />\\1' + callout_text, enhanced_content, count=1)\n",
    "    elif first_header_match:\n",
    "        # Otherwise place it directly after the first header\n",
    "        header_end = first_header_match.end()\n",
    "        enhanced_content = enhanced_content[:header_end] + '\\n' + callout_text + enhanced_content[header_end:]\n",
    "    \n",
    "    # Apply TwoColumn layout if recommended\n",
    "    if layout.get(\"recommended\", False) and layout.get(\"type\", \"\") == \"TwoColumn\":\n",
    "        # Find all level 2 headers and wrap their sections in TwoColumn\n",
    "        h2_sections = re.findall(r'(## .+?)(?=\\n## |\\Z)', enhanced_content, re.DOTALL)\n",
    "        \n",
    "        if len(h2_sections) > 1:\n",
    "            # Only apply TwoColumn if we have multiple sections\n",
    "            new_content = \"\"\n",
    "            for i, section in enumerate(h2_sections):\n",
    "                if i % 2 == 0 and i+1 < len(h2_sections):\n",
    "                    # Start a new TwoColumn for every pair of sections\n",
    "                    new_content += f'<TwoColumn>\\n<div>\\n{section}\\n</div>\\n<div>\\n{h2_sections[i+1]}\\n</div>\\n</TwoColumn>\\n\\n'\n",
    "                elif i % 2 == 1:\n",
    "                    # Skip odd indices as they're handled in the previous iteration\n",
    "                    continue\n",
    "                else:\n",
    "                    # Handle any remaining section\n",
    "                    new_content += section\n",
    "            \n",
    "            # Replace the content after the first heading (preserving intro and TOC)\n",
    "            first_heading_end = first_header_match.end()\n",
    "            intro_content = enhanced_content[:first_heading_end]\n",
    "            \n",
    "            # Check if we have TOC and callout\n",
    "            toc_callout_match = re.search(r'\\n\\n<TableOfContents />.+?<\\/CalloutBox>\\n\\n', enhanced_content[first_heading_end:], re.DOTALL)\n",
    "            if toc_callout_match:\n",
    "                intro_content += enhanced_content[first_heading_end:first_heading_end+toc_callout_match.end()]\n",
    "                enhanced_content = intro_content + new_content\n",
    "            else:\n",
    "                # Check if we just have callout\n",
    "                callout_match = re.search(r'\\n<CalloutBox.+?<\\/CalloutBox>\\n\\n', enhanced_content[first_heading_end:], re.DOTALL)\n",
    "                if callout_match:\n",
    "                    intro_content += enhanced_content[first_heading_end:first_heading_end+callout_match.end()]\n",
    "                    enhanced_content = intro_content + new_content\n",
    "                else:\n",
    "                    enhanced_content = intro_content + new_content\n",
    "    \n",
    "    # Combine all parts into the final MDX content\n",
    "    mdx_content = frontmatter_yaml + imports_text + enhanced_content\n",
    "    \n",
    "    interactive_element_keys = [\n",
    "        key for key, value in interactive_elements.items() \n",
    "        if isinstance(value, dict) and value.get(\"recommended\", False)\n",
    "    ]\n",
    "    \n",
    "    media_enhancement_keys = [\n",
    "        key for key, value in media_enhancements.items() \n",
    "        if isinstance(value, dict) and value.get(\"recommended\", False)\n",
    "    ]\n",
    "    \n",
    "    return {\n",
    "        \"mdx_content\": mdx_content,\n",
    "        \"components_used\": components_used,\n",
    "        \"interactive_elements\": interactive_element_keys,\n",
    "        \"media_enhancements\": media_enhancement_keys\n",
    "    }\n",
    "\n",
    "def analyze_transformation(original_markdown: Dict[str, Any], mdx_result: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Analyze the transformation from markdown to MDX.\"\"\"\n",
    "    \n",
    "    original_content = original_markdown.get(\"content\", \"\")\n",
    "    mdx_content = mdx_result.get(\"mdx_content\", \"\")\n",
    "    \n",
    "    # Calculate statistics\n",
    "    original_lines = len(original_content.split(\"\\n\"))\n",
    "    mdx_lines = len(mdx_content.split(\"\\n\"))\n",
    "    \n",
    "    original_words = len(original_content.split())\n",
    "    mdx_words = len(mdx_content.split())\n",
    "    \n",
    "    components_used = mdx_result.get(\"components_used\", [])\n",
    "    interactive_elements = mdx_result.get(\"interactive_elements\", [])\n",
    "    media_enhancements = mdx_result.get(\"media_enhancements\", [])\n",
    "    \n",
    "    # Create an analysis report\n",
    "    analysis = {\n",
    "        \"original_lines\": original_lines,\n",
    "        \"mdx_lines\": mdx_lines,\n",
    "        \"line_change\": mdx_lines - original_lines,\n",
    "        \"line_change_percentage\": ((mdx_lines - original_lines) / original_lines * 100) if original_lines > 0 else 0,\n",
    "        \n",
    "        \"original_words\": original_words,\n",
    "        \"mdx_words\": mdx_words,\n",
    "        \"word_change\": mdx_words - original_words,\n",
    "        \"word_change_percentage\": ((mdx_words - original_words) / original_words * 100) if original_words > 0 else 0,\n",
    "        \n",
    "        \"components_used\": components_used,\n",
    "        \"components_count\": len(components_used),\n",
    "        \"interactive_elements\": interactive_elements,\n",
    "        \"media_enhancements\": media_enhancements,\n",
    "    }\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "def save_mdx_file(mdx_content: str, output_path: str) -> str:\n",
    "    \"\"\"Save MDX content to a file.\"\"\"\n",
    "    try:\n",
    "        # Ensure the directory exists\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        \n",
    "        # Write the content\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(mdx_content)\n",
    "        \n",
    "        console.print(f\"[green]MDX file saved to: {output_path}[/green]\")\n",
    "        return output_path\n",
    "    \n",
    "    except Exception as e:\n",
    "        console.print(f\"[red]Error saving MDX file to {output_path}: {str(e)}[/red]\")\n",
    "        return \"\"\n",
    "\n",
    "print(\"Transformation functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4d9d6dc-ddc4-4e79-a39d-bf33cc9404d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report generation functions defined.\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Report Generation Functions\n",
    "\n",
    "def create_analysis_report(file_name: str, markdown_data: Dict[str, Any], analysis: Dict[str, Any]) -> str:\n",
    "    \"\"\"Create a human-readable analysis report.\"\"\"\n",
    "    \n",
    "    # Create the header\n",
    "    report = f\"# MDX Enhancement Analysis for {file_name}\\n\\n\"\n",
    "    \n",
    "    # Add content structure summary\n",
    "    report += f\"## Content Structure\\n\\n\"\n",
    "    report += f\"- **Headers**: {len(markdown_data['structure']['headers'])}\\n\"\n",
    "    report += f\"- **Code Blocks**: {len(markdown_data['structure']['code_blocks'])}\\n\"\n",
    "    report += f\"- **Images**: {len(markdown_data['structure']['images'])}\\n\"\n",
    "    report += f\"- **Lists**: {markdown_data['structure']['list_blocks']}\\n\"\n",
    "    report += f\"- **Tables**: {markdown_data['structure']['tables']}\\n\"\n",
    "    report += f\"- **Paragraphs**: {markdown_data['structure']['paragraphs']}\\n\"\n",
    "    report += f\"- **Word Count**: {markdown_data['structure']['word_count']}\\n\\n\"\n",
    "    \n",
    "    # Add interactive elements recommendations\n",
    "    report += f\"## Recommended Interactive Elements\\n\\n\"\n",
    "    \n",
    "    interactive_elements = analysis.get(\"interactive_elements\", {})\n",
    "    for key, value in interactive_elements.items():\n",
    "        if isinstance(value, dict) and \"reason\" in value:\n",
    "            recommended = value.get(\"recommended\", False)\n",
    "            reason = value.get(\"reason\", \"\")\n",
    "            status = \"✅ Recommended\" if recommended else \"❌ Not recommended\"\n",
    "            report += f\"- **{key}**: {status}\\n  {reason}\\n\\n\"\n",
    "    \n",
    "    # Add media enhancement recommendations\n",
    "    report += f\"## Recommended Media Enhancements\\n\\n\"\n",
    "    \n",
    "    media_enhancements = analysis.get(\"media_enhancements\", {})\n",
    "    for key, value in media_enhancements.items():\n",
    "        if isinstance(value, dict) and \"reason\" in value:\n",
    "            recommended = value.get(\"recommended\", False)\n",
    "            reason = value.get(\"reason\", \"\")\n",
    "            status = \"✅ Recommended\" if recommended else \"❌ Not recommended\"\n",
    "            report += f\"- **{key}**: {status}\\n  {reason}\\n\\n\"\n",
    "    \n",
    "    # Add analysis summary\n",
    "    if \"analysis\" in analysis:\n",
    "        report += f\"## Analysis Summary\\n\\n{analysis.get('analysis', '')}\\n\\n\"\n",
    "    \n",
    "    # Add special suggestions\n",
    "    if \"special_suggestions\" in analysis:\n",
    "        report += f\"## Special Suggestions\\n\\n{analysis.get('special_suggestions', '')}\\n\"\n",
    "    \n",
    "    return report\n",
    "\n",
    "def create_transformation_report(file_name: str, transformation_analysis: Dict[str, Any]) -> str:\n",
    "    \"\"\"Create a human-readable transformation report.\"\"\"\n",
    "    \n",
    "    # Create the header\n",
    "    report = f\"# MDX Transformation Report for {file_name}\\n\\n\"\n",
    "    \n",
    "    # Add transformation metrics\n",
    "    report += f\"## Transformation Metrics\\n\\n\"\n",
    "    report += f\"- **Original Lines**: {transformation_analysis['original_lines']}\\n\"\n",
    "    report += f\"- **MDX Lines**: {transformation_analysis['mdx_lines']}\\n\"\n",
    "    report += f\"- **Line Change**: {transformation_analysis['line_change']} ({transformation_analysis['line_change_percentage']:.1f}%)\\n\"\n",
    "    report += f\"- **Original Words**: {transformation_analysis['original_words']}\\n\"\n",
    "    report += f\"- **MDX Words**: {transformation_analysis['mdx_words']}\\n\"\n",
    "    report += f\"- **Word Change**: {transformation_analysis['word_change']} ({transformation_analysis['word_change_percentage']:.1f}%)\\n\\n\"\n",
    "    \n",
    "    # Add components used\n",
    "    report += f\"## Components Used\\n\\n\"\n",
    "    for component in transformation_analysis['components_used']:\n",
    "        report += f\"- **{component}**\\n\"\n",
    "    \n",
    "    return report\n",
    "\n",
    "def create_summary_report(results: List[Dict[str, Any]], output_dir: str) -> str:\n",
    "    \"\"\"Create a summary report of all transformations.\"\"\"\n",
    "    \n",
    "    # Filter results\n",
    "    successful = [r for r in results if r[\"success\"]]\n",
    "    failed = [r for r in results if not r[\"success\"]]\n",
    "    \n",
    "    # Create the header\n",
    "    report = \"# MDX Transformation Summary\\n\\n\"\n",
    "    report += f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\"\n",
    "    \n",
    "    # Add transformation results\n",
    "    report += \"## Transformation Results\\n\\n\"\n",
    "    report += f\"- Total Files Processed: {len(results)}\\n\"\n",
    "    report += f\"- Successful Transformations: {len(successful)}\\n\"\n",
    "    report += f\"- Failed Transformations: {len(failed)}\\n\\n\"\n",
    "    \n",
    "    # Add component usage statistics\n",
    "    all_components_used = []\n",
    "    for result in successful:\n",
    "        all_components_used.extend(result.get(\"components_used\", []))\n",
    "    \n",
    "    component_counts = {}\n",
    "    for component in all_components_used:\n",
    "        if component in component_counts:\n",
    "            component_counts[component] += 1\n",
    "        else:\n",
    "            component_counts[component] = 1\n",
    "    \n",
    "    if component_counts:\n",
    "        report += \"## Component Usage\\n\\n\"\n",
    "        for component, count in sorted(component_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "            report += f\"- **{component}**: {count} files\\n\"\n",
    "        report += \"\\n\"\n",
    "    \n",
    "    # List successful transformations\n",
    "    report += \"## Successful Transformations\\n\\n\"\n",
    "    report += \"| # | File | Components | Word Count | MDX Output |\\n\"\n",
    "    report += \"|---|------|------------|------------|------------|\\n\"\n",
    "    \n",
    "    for i, result in enumerate(successful):\n",
    "        file_name = result.get(\"file_name\", \"Unknown\")\n",
    "        components_count = len(result.get(\"components_used\", []))\n",
    "        components_list = \", \".join(result.get(\"components_used\", [])[:3])\n",
    "        if len(result.get(\"components_used\", [])) > 3:\n",
    "            components_list += f\" +{len(result.get('components_used', [])) - 3} more\"\n",
    "        \n",
    "        word_count = result.get(\"analysis\", {}).get(\"mdx_words\", 0)\n",
    "        output_path = result.get(\"output_mdx_path\", \"\")\n",
    "        relative_output = os.path.relpath(output_path, output_dir) if output_path else \"\"\n",
    "        \n",
    "        report += f\"| {i+1} | {file_name} | {components_list} | {word_count} | [{relative_output}](./{relative_output}) |\\n\"\n",
    "    \n",
    "    # List failed transformations\n",
    "    if failed:\n",
    "        report += \"\\n## Failed Transformations\\n\\n\"\n",
    "        report += \"| # | File | Error |\\n\"\n",
    "        report += \"|---|------|-------|\\n\"\n",
    "        \n",
    "        for i, result in enumerate(failed):\n",
    "            file_name = result.get(\"file_name\", \"Unknown\")\n",
    "            error = result.get(\"errors\", [\"Unknown error\"])[0]\n",
    "            \n",
    "            report += f\"| {i+1} | {file_name} | {error} |\\n\"\n",
    "    \n",
    "    # Add process description\n",
    "    report += \"\\n## Process Description\\n\\n\"\n",
    "    report += \"Each markdown file went through the following transformation process:\\n\\n\"\n",
    "    report += \"1. **Content Analysis**: Analyzed the structure and content of the markdown file using Gemini AI\\n\"\n",
    "    report += \"2. **MDX Enhancement**: Identified opportunities for interactive components\\n\"\n",
    "    report += \"3. **MDX Transformation**: Converted markdown to MDX with interactive components\\n\"\n",
    "    report += \"4. **Transformation Analysis**: Evaluated the transformation quality and effectiveness\\n\\n\"\n",
    "    \n",
    "    report += \"Each file directory contains detailed logs of each step in the process.\\n\"\n",
    "    \n",
    "    return report\n",
    "\n",
    "print(\"Report generation functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd91e1f2-041b-4fce-9872-9acbb933c51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File processing functions defined.\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: File Processing Functions\n",
    "\n",
    "async def process_markdown_file(file_path: str, output_dir: str = OUTPUT_DIR) -> Dict[str, Any]:\n",
    "    \"\"\"Process a single markdown file into an interactive MDX file.\"\"\"\n",
    "    \n",
    "    file_name = os.path.basename(file_path)\n",
    "    file_stem = os.path.splitext(file_name)[0]\n",
    "    \n",
    "    console.print(f\"\\n[bold blue]Processing:[/bold blue] {file_path}\")\n",
    "    \n",
    "    # Create a directory for this file's artifacts\n",
    "    file_output_dir = os.path.join(output_dir, file_stem)\n",
    "    os.makedirs(file_output_dir, exist_ok=True)\n",
    "    \n",
    "    results = {\n",
    "        \"file_path\": file_path,\n",
    "        \"file_name\": file_name,\n",
    "        \"success\": False,\n",
    "        \"output_mdx_path\": \"\",\n",
    "        \"components_used\": [],\n",
    "        \"interactive_elements\": [],\n",
    "        \"media_enhancements\": [],\n",
    "        \"analysis\": {},\n",
    "        \"errors\": []\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # STEP 1: Parse the markdown\n",
    "        console.print(f\"  Step 1: Parsing markdown content...\")\n",
    "        markdown_data = parse_markdown(file_path)\n",
    "        \n",
    "        if \"error\" in markdown_data and markdown_data[\"error\"]:\n",
    "            raise Exception(f\"Failed to parse markdown: {markdown_data['error']}\")\n",
    "        \n",
    "        # Save parsed markdown data\n",
    "        parsed_data_path = os.path.join(file_output_dir, \"01_parsed_markdown.json\")\n",
    "        with open(parsed_data_path, \"w\") as f:\n",
    "            # Convert structure to a serializable format for images and code blocks\n",
    "            serializable_data = {**markdown_data}\n",
    "            serializable_data[\"structure\"] = {\n",
    "                \"headers\": serializable_data[\"structure\"][\"headers\"],\n",
    "                \"code_blocks\": [\n",
    "                    {\"language\": block[\"language\"], \"content_length\": len(block[\"content\"])} \n",
    "                    for block in serializable_data[\"structure\"][\"code_blocks\"]\n",
    "                ],\n",
    "                \"images\": [\n",
    "                    {\"alt\": img[\"alt\"], \"src\": img[\"src\"]} \n",
    "                    for img in serializable_data[\"structure\"][\"images\"]\n",
    "                ],\n",
    "                \"links\": serializable_data[\"structure\"][\"links\"],\n",
    "                \"list_blocks\": serializable_data[\"structure\"][\"list_blocks\"],\n",
    "                \"tables\": serializable_data[\"structure\"][\"tables\"],\n",
    "                \"paragraphs\": serializable_data[\"structure\"][\"paragraphs\"],\n",
    "                \"word_count\": serializable_data[\"structure\"][\"word_count\"]\n",
    "            }\n",
    "            json.dump(serializable_data, f, indent=2)\n",
    "        \n",
    "        # STEP 2: Analyze content for MDX opportunities using Gemini AI\n",
    "        console.print(f\"  Step 2: Analyzing content for MDX enhancement opportunities...\")\n",
    "        analysis = await analyze_content_with_ai(markdown_data)\n",
    "        \n",
    "        # Save analysis\n",
    "        analysis_path = os.path.join(file_output_dir, \"02_mdx_analysis.json\")\n",
    "        with open(analysis_path, \"w\") as f:\n",
    "            json.dump(analysis, f, indent=2)\n",
    "        \n",
    "        # Create a human-readable analysis report\n",
    "        analysis_report = create_analysis_report(file_name, markdown_data, analysis)\n",
    "        \n",
    "        # Save human-readable analysis\n",
    "        analysis_report_path = os.path.join(file_output_dir, \"02_enhancement_analysis.md\")\n",
    "        with open(analysis_report_path, \"w\") as f:\n",
    "            f.write(analysis_report)\n",
    "        \n",
    "        # STEP 3: Transform to MDX\n",
    "        console.print(f\"  Step 3: Transforming to interactive MDX...\")\n",
    "        mdx_result = transform_to_mdx(markdown_data, analysis)\n",
    "        \n",
    "        # Extract MDX content\n",
    "        mdx_content = mdx_result.get(\"mdx_content\", \"\")\n",
    "        \n",
    "        # Save MDX content\n",
    "        mdx_output_path = os.path.join(file_output_dir, f\"{file_stem}.mdx\")\n",
    "        save_mdx_file(mdx_content, mdx_output_path)\n",
    "        \n",
    "        # STEP 4: Analyze transformation\n",
    "        console.print(f\"  Step 4: Analyzing transformation results...\")\n",
    "        transformation_analysis = analyze_transformation(markdown_data, mdx_result)\n",
    "        \n",
    "        # Save transformation analysis\n",
    "        transform_analysis_path = os.path.join(file_output_dir, \"03_transformation_analysis.json\")\n",
    "        with open(transform_analysis_path, \"w\") as f:\n",
    "            json.dump(transformation_analysis, f, indent=2)\n",
    "        \n",
    "        # Create a human-readable transformation report\n",
    "        transform_report = create_transformation_report(file_name, transformation_analysis)\n",
    "        \n",
    "        # Save human-readable transformation report\n",
    "        transform_report_path = os.path.join(file_output_dir, \"03_transformation_report.md\")\n",
    "        with open(transform_report_path, \"w\") as f:\n",
    "            f.write(transform_report)\n",
    "        \n",
    "        # Update results\n",
    "        results.update({\n",
    "            \"success\": True,\n",
    "            \"output_mdx_path\": mdx_output_path,\n",
    "            \"components_used\": mdx_result.get(\"components_used\", []),\n",
    "            \"interactive_elements\": mdx_result.get(\"interactive_elements\", []),\n",
    "            \"media_enhancements\": mdx_result.get(\"media_enhancements\", []),\n",
    "            \"analysis\": transformation_analysis\n",
    "        })\n",
    "        \n",
    "        console.print(f\"[bold green]✓ Completed:[/bold green] {file_path} -> {mdx_output_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_message = f\"Error processing {file_path}: {str(e)}\"\n",
    "        console.print(f\"[bold red]Error:[/bold red] {error_message}\")\n",
    "        results[\"errors\"].append(error_message)\n",
    "        \n",
    "        # Save error log\n",
    "        error_log_path = os.path.join(file_output_dir, \"error_log.md\")\n",
    "        with open(error_log_path, \"w\") as f:\n",
    "            f.write(f\"# Error Log: {file_name}\\n\\n\")\n",
    "            f.write(f\"## Error Message\\n\\n\")\n",
    "            f.write(f\"{error_message}\\n\\n\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "async def process_markdown_directory(directory_path: str) -> Dict[str, Any]:\n",
    "    \"\"\"Process all markdown files in a directory into interactive MDX files.\"\"\"\n",
    "    console.print(f\"\\n[bold]MDX Transformer: Processing directory {directory_path}[/bold]\")\n",
    "    \n",
    "    # Find all markdown files in the directory\n",
    "    markdown_files = glob.glob(f\"{directory_path}/**/*.md\", recursive=True)\n",
    "    \n",
    "    if not markdown_files:\n",
    "        console.print(f\"[bold yellow]No markdown files found in {directory_path}[/bold yellow]\")\n",
    "        return {\n",
    "            \"status\": \"completed\",\n",
    "            \"files_processed\": 0,\n",
    "            \"successful_transformations\": 0,\n",
    "            \"failed_transformations\": 0,\n",
    "            \"output_directory\": OUTPUT_DIR,\n",
    "            \"results\": []\n",
    "        }\n",
    "    \n",
    "    console.print(f\"[bold]Found {len(markdown_files)} markdown files to process[/bold]\")\n",
    "    console.print(f\"[bold]Output directory: {OUTPUT_DIR}[/bold]\")\n",
    "    \n",
    "    # Process each file\n",
    "    results = []\n",
    "    for file_path in tqdm(markdown_files, desc=\"Processing files\"):\n",
    "        result = await process_markdown_file(\n",
    "            file_path=file_path,\n",
    "            output_dir=OUTPUT_DIR\n",
    "        )\n",
    "        results.append(result)\n",
    "    \n",
    "    # Create summary report\n",
    "    summary_report = create_summary_report(results, OUTPUT_DIR)\n",
    "    \n",
    "    # Save summary report\n",
    "    summary_path = os.path.join(OUTPUT_DIR, \"00_transformation_summary.md\")\n",
    "    with open(summary_path, \"w\") as f:\n",
    "        f.write(summary_report)\n",
    "    \n",
    "    # Count successful and failed transformations\n",
    "    successful = [r for r in results if r[\"success\"]]\n",
    "    failed = [r for r in results if not r[\"success\"]]\n",
    "    \n",
    "    console.print(f\"\\n[bold green]Transformation process completed![/bold green]\")\n",
    "    console.print(f\"Processed {len(results)} files\")\n",
    "    console.print(f\"Successful transformations: {len(successful)}\")\n",
    "    console.print(f\"Failed transformations: {len(failed)}\")\n",
    "    console.print(f\"Summary available at: {summary_path}\")\n",
    "    \n",
    "    return {\n",
    "        \"status\": \"completed\",\n",
    "        \"files_processed\": len(results),\n",
    "        \"successful_transformations\": len(successful),\n",
    "        \"failed_transformations\": len(failed),\n",
    "        \"output_directory\": OUTPUT_DIR,\n",
    "        \"summary_file\": summary_path,\n",
    "        \"results\": results\n",
    "    }\n",
    "\n",
    "print(\"File processing functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81492a13-b605-4a89-b8cf-6efce203b6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to process all files in mvp_launch_markdown? (y/n):  y\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Starting to process all files in mvp_launch_markdown<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Starting to process all files in mvp_launch_markdown\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">MDX Transformer: Processing directory mvp_launch_markdown</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1mMDX Transformer: Processing directory mvp_launch_markdown\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Found </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span><span style=\"font-weight: bold\"> markdown files to process</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mFound \u001b[0m\u001b[1;36m9\u001b[0m\u001b[1m markdown files to process\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Output directory: MDX_Transformed_20250520_203251</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mOutput directory: MDX_Transformed_20250520_203251\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d321146bdcd4fdabc6386dac1e196dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing files:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Processing:</span> mvp_launch_markdown/05_Job_Search_101_Your_Roadmap_to_Landing_Your_Dream_Job.md\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;34mProcessing:\u001b[0m mvp_launch_markdown/05_Job_Search_101_Your_Roadmap_to_Landing_Your_Dream_Job.md\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: Parsing markdown content<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Step \u001b[1;36m1\u001b[0m: Parsing markdown content\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Parsing markdown file: mvp_launch_markdown/05_Job_Search_101_Your_Roadmap_to_Landing_Your_Dream_Job.md\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Parsing markdown file: mvp_launch_markdown/05_Job_Search_101_Your_Roadmap_to_Landing_Your_Dream_Job.md\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: Analyzing content for MDX enhancement opportunities<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Step \u001b[1;36m2\u001b[0m: Analyzing content for MDX enhancement opportunities\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Using Gemini to analyze content and suggest enhancements<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Using Gemini to analyze content and suggest enhancements\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Error using Gemini for analysis: </span><span style=\"color: #808000; text-decoration-color: #808000\">'Client'</span><span style=\"color: #808000; text-decoration-color: #808000\"> object has no attribute </span><span style=\"color: #808000; text-decoration-color: #808000\">'generate_content'</span><span style=\"color: #808000; text-decoration-color: #808000\">. Using rule-based analysis </span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">instead.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mError using Gemini for analysis: \u001b[0m\u001b[33m'Client'\u001b[0m\u001b[33m object has no attribute \u001b[0m\u001b[33m'generate_content'\u001b[0m\u001b[33m. Using rule-based analysis \u001b[0m\n",
       "\u001b[33minstead.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>: Transforming to interactive MDX<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Step \u001b[1;36m3\u001b[0m: Transforming to interactive MDX\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">MDX file saved to: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">MDX_Transformed_20250520_203251/05_Job_Search_101_Your_Roadmap_to_Landing_Your_Dream_Job/05_Job_Search_101_Your_Roa</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">dmap_to_Landing_Your_Dream_Job.mdx</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mMDX file saved to: \u001b[0m\n",
       "\u001b[32mMDX_Transformed_20250520_203251/05_Job_Search_101_Your_Roadmap_to_Landing_Your_Dream_Job/05_Job_Search_101_Your_Roa\u001b[0m\n",
       "\u001b[32mdmap_to_Landing_Your_Dream_Job.mdx\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>: Analyzing transformation results<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Step \u001b[1;36m4\u001b[0m: Analyzing transformation results\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✓ Completed:</span> mvp_launch_markdown/05_Job_Search_101_Your_Roadmap_to_Landing_Your_Dream_Job.md -&gt; \n",
       "MDX_Transformed_20250520_203251/05_Job_Search_101_Your_Roadmap_to_Landing_Your_Dream_Job/05_Job_Search_101_Your_Roa\n",
       "dmap_to_Landing_Your_Dream_Job.mdx\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m✓ Completed:\u001b[0m mvp_launch_markdown/05_Job_Search_101_Your_Roadmap_to_Landing_Your_Dream_Job.md -> \n",
       "MDX_Transformed_20250520_203251/05_Job_Search_101_Your_Roadmap_to_Landing_Your_Dream_Job/05_Job_Search_101_Your_Roa\n",
       "dmap_to_Landing_Your_Dream_Job.mdx\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Processing:</span> mvp_launch_markdown/01_Introducing_MaryJobins_Your_AI-Powered_Job_Search_Assistant.md\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;34mProcessing:\u001b[0m mvp_launch_markdown/01_Introducing_MaryJobins_Your_AI-Powered_Job_Search_Assistant.md\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: Parsing markdown content<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Step \u001b[1;36m1\u001b[0m: Parsing markdown content\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Parsing markdown file: mvp_launch_markdown/01_Introducing_MaryJobins_Your_AI-Powered_Job_Search_Assistant.md\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Parsing markdown file: mvp_launch_markdown/01_Introducing_MaryJobins_Your_AI-Powered_Job_Search_Assistant.md\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: Analyzing content for MDX enhancement opportunities<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Step \u001b[1;36m2\u001b[0m: Analyzing content for MDX enhancement opportunities\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Using Gemini to analyze content and suggest enhancements<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Using Gemini to analyze content and suggest enhancements\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Error using Gemini for analysis: </span><span style=\"color: #808000; text-decoration-color: #808000\">'Client'</span><span style=\"color: #808000; text-decoration-color: #808000\"> object has no attribute </span><span style=\"color: #808000; text-decoration-color: #808000\">'generate_content'</span><span style=\"color: #808000; text-decoration-color: #808000\">. Using rule-based analysis </span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">instead.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mError using Gemini for analysis: \u001b[0m\u001b[33m'Client'\u001b[0m\u001b[33m object has no attribute \u001b[0m\u001b[33m'generate_content'\u001b[0m\u001b[33m. Using rule-based analysis \u001b[0m\n",
       "\u001b[33minstead.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>: Transforming to interactive MDX<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Step \u001b[1;36m3\u001b[0m: Transforming to interactive MDX\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">MDX file saved to: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">MDX_Transformed_20250520_203251/01_Introducing_MaryJobins_Your_AI-Powered_Job_Search_Assistant/01_Introducing_MaryJ</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">obins_Your_AI-Powered_Job_Search_Assistant.mdx</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mMDX file saved to: \u001b[0m\n",
       "\u001b[32mMDX_Transformed_20250520_203251/01_Introducing_MaryJobins_Your_AI-Powered_Job_Search_Assistant/01_Introducing_MaryJ\u001b[0m\n",
       "\u001b[32mobins_Your_AI-Powered_Job_Search_Assistant.mdx\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>: Analyzing transformation results<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Step \u001b[1;36m4\u001b[0m: Analyzing transformation results\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✓ Completed:</span> mvp_launch_markdown/01_Introducing_MaryJobins_Your_AI-Powered_Job_Search_Assistant.md -&gt; \n",
       "MDX_Transformed_20250520_203251/01_Introducing_MaryJobins_Your_AI-Powered_Job_Search_Assistant/01_Introducing_MaryJ\n",
       "obins_Your_AI-Powered_Job_Search_Assistant.mdx\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m✓ Completed:\u001b[0m mvp_launch_markdown/01_Introducing_MaryJobins_Your_AI-Powered_Job_Search_Assistant.md -> \n",
       "MDX_Transformed_20250520_203251/01_Introducing_MaryJobins_Your_AI-Powered_Job_Search_Assistant/01_Introducing_MaryJ\n",
       "obins_Your_AI-Powered_Job_Search_Assistant.mdx\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Processing:</span> mvp_launch_markdown/03_Unlocking_Potential_How_MaryJobins_Parses_Your_Resume_for_Perfect_Matches.md\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;34mProcessing:\u001b[0m mvp_launch_markdown/03_Unlocking_Potential_How_MaryJobins_Parses_Your_Resume_for_Perfect_Matches.md\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: Parsing markdown content<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Step \u001b[1;36m1\u001b[0m: Parsing markdown content\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Parsing markdown file: \n",
       "mvp_launch_markdown/03_Unlocking_Potential_How_MaryJobins_Parses_Your_Resume_for_Perfect_Matches.md\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Parsing markdown file: \n",
       "mvp_launch_markdown/03_Unlocking_Potential_How_MaryJobins_Parses_Your_Resume_for_Perfect_Matches.md\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: Analyzing content for MDX enhancement opportunities<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Step \u001b[1;36m2\u001b[0m: Analyzing content for MDX enhancement opportunities\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Using Gemini to analyze content and suggest enhancements<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Using Gemini to analyze content and suggest enhancements\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Error using Gemini for analysis: </span><span style=\"color: #808000; text-decoration-color: #808000\">'Client'</span><span style=\"color: #808000; text-decoration-color: #808000\"> object has no attribute </span><span style=\"color: #808000; text-decoration-color: #808000\">'generate_content'</span><span style=\"color: #808000; text-decoration-color: #808000\">. Using rule-based analysis </span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">instead.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mError using Gemini for analysis: \u001b[0m\u001b[33m'Client'\u001b[0m\u001b[33m object has no attribute \u001b[0m\u001b[33m'generate_content'\u001b[0m\u001b[33m. Using rule-based analysis \u001b[0m\n",
       "\u001b[33minstead.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>: Transforming to interactive MDX<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Step \u001b[1;36m3\u001b[0m: Transforming to interactive MDX\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">MDX file saved to: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">MDX_Transformed_20250520_203251/03_Unlocking_Potential_How_MaryJobins_Parses_Your_Resume_for_Perfect_Matches/03_Unl</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ocking_Potential_How_MaryJobins_Parses_Your_Resume_for_Perfect_Matches.mdx</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mMDX file saved to: \u001b[0m\n",
       "\u001b[32mMDX_Transformed_20250520_203251/03_Unlocking_Potential_How_MaryJobins_Parses_Your_Resume_for_Perfect_Matches/03_Unl\u001b[0m\n",
       "\u001b[32mocking_Potential_How_MaryJobins_Parses_Your_Resume_for_Perfect_Matches.mdx\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>: Analyzing transformation results<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Step \u001b[1;36m4\u001b[0m: Analyzing transformation results\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✓ Completed:</span> mvp_launch_markdown/03_Unlocking_Potential_How_MaryJobins_Parses_Your_Resume_for_Perfect_Matches.md -&gt;\n",
       "MDX_Transformed_20250520_203251/03_Unlocking_Potential_How_MaryJobins_Parses_Your_Resume_for_Perfect_Matches/03_Unl\n",
       "ocking_Potential_How_MaryJobins_Parses_Your_Resume_for_Perfect_Matches.mdx\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m✓ Completed:\u001b[0m mvp_launch_markdown/03_Unlocking_Potential_How_MaryJobins_Parses_Your_Resume_for_Perfect_Matches.md ->\n",
       "MDX_Transformed_20250520_203251/03_Unlocking_Potential_How_MaryJobins_Parses_Your_Resume_for_Perfect_Matches/03_Unl\n",
       "ocking_Potential_How_MaryJobins_Parses_Your_Resume_for_Perfect_Matches.mdx\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Processing:</span> mvp_launch_markdown/04_5_Job_Search_Mistakes_That_Could_Be_Costing_You_Your_Dream_Job.md\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;34mProcessing:\u001b[0m mvp_launch_markdown/04_5_Job_Search_Mistakes_That_Could_Be_Costing_You_Your_Dream_Job.md\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: Parsing markdown content<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Step \u001b[1;36m1\u001b[0m: Parsing markdown content\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Parsing markdown file: mvp_launch_markdown/04_5_Job_Search_Mistakes_That_Could_Be_Costing_You_Your_Dream_Job.md\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Parsing markdown file: mvp_launch_markdown/04_5_Job_Search_Mistakes_That_Could_Be_Costing_You_Your_Dream_Job.md\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: Analyzing content for MDX enhancement opportunities<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Step \u001b[1;36m2\u001b[0m: Analyzing content for MDX enhancement opportunities\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Using Gemini to analyze content and suggest enhancements<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Using Gemini to analyze content and suggest enhancements\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Error using Gemini for analysis: </span><span style=\"color: #808000; text-decoration-color: #808000\">'Client'</span><span style=\"color: #808000; text-decoration-color: #808000\"> object has no attribute </span><span style=\"color: #808000; text-decoration-color: #808000\">'generate_content'</span><span style=\"color: #808000; text-decoration-color: #808000\">. Using rule-based analysis </span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">instead.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mError using Gemini for analysis: \u001b[0m\u001b[33m'Client'\u001b[0m\u001b[33m object has no attribute \u001b[0m\u001b[33m'generate_content'\u001b[0m\u001b[33m. Using rule-based analysis \u001b[0m\n",
       "\u001b[33minstead.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>: Transforming to interactive MDX<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Step \u001b[1;36m3\u001b[0m: Transforming to interactive MDX\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">MDX file saved to: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">MDX_Transformed_20250520_203251/04_5_Job_Search_Mistakes_That_Could_Be_Costing_You_Your_Dream_Job/04_5_Job_Search_M</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">istakes_That_Could_Be_Costing_You_Your_Dream_Job.mdx</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mMDX file saved to: \u001b[0m\n",
       "\u001b[32mMDX_Transformed_20250520_203251/04_5_Job_Search_Mistakes_That_Could_Be_Costing_You_Your_Dream_Job/04_5_Job_Search_M\u001b[0m\n",
       "\u001b[32mistakes_That_Could_Be_Costing_You_Your_Dream_Job.mdx\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>: Analyzing transformation results<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Step \u001b[1;36m4\u001b[0m: Analyzing transformation results\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✓ Completed:</span> mvp_launch_markdown/04_5_Job_Search_Mistakes_That_Could_Be_Costing_You_Your_Dream_Job.md -&gt; \n",
       "MDX_Transformed_20250520_203251/04_5_Job_Search_Mistakes_That_Could_Be_Costing_You_Your_Dream_Job/04_5_Job_Search_M\n",
       "istakes_That_Could_Be_Costing_You_Your_Dream_Job.mdx\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m✓ Completed:\u001b[0m mvp_launch_markdown/04_5_Job_Search_Mistakes_That_Could_Be_Costing_You_Your_Dream_Job.md -> \n",
       "MDX_Transformed_20250520_203251/04_5_Job_Search_Mistakes_That_Could_Be_Costing_You_Your_Dream_Job/04_5_Job_Search_M\n",
       "istakes_That_Could_Be_Costing_You_Your_Dream_Job.mdx\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Processing:</span> mvp_launch_markdown/08_Understanding_Modern_ATS_Systems_What_Job_Seekers_Need_to_Know.md\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;34mProcessing:\u001b[0m mvp_launch_markdown/08_Understanding_Modern_ATS_Systems_What_Job_Seekers_Need_to_Know.md\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: Parsing markdown content<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Step \u001b[1;36m1\u001b[0m: Parsing markdown content\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Parsing markdown file: mvp_launch_markdown/08_Understanding_Modern_ATS_Systems_What_Job_Seekers_Need_to_Know.md\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Parsing markdown file: mvp_launch_markdown/08_Understanding_Modern_ATS_Systems_What_Job_Seekers_Need_to_Know.md\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: Analyzing content for MDX enhancement opportunities<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Step \u001b[1;36m2\u001b[0m: Analyzing content for MDX enhancement opportunities\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Using Gemini to analyze content and suggest enhancements<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Using Gemini to analyze content and suggest enhancements\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Error using Gemini for analysis: </span><span style=\"color: #808000; text-decoration-color: #808000\">'Client'</span><span style=\"color: #808000; text-decoration-color: #808000\"> object has no attribute </span><span style=\"color: #808000; text-decoration-color: #808000\">'generate_content'</span><span style=\"color: #808000; text-decoration-color: #808000\">. Using rule-based analysis </span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">instead.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mError using Gemini for analysis: \u001b[0m\u001b[33m'Client'\u001b[0m\u001b[33m object has no attribute \u001b[0m\u001b[33m'generate_content'\u001b[0m\u001b[33m. Using rule-based analysis \u001b[0m\n",
       "\u001b[33minstead.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>: Transforming to interactive MDX<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Step \u001b[1;36m3\u001b[0m: Transforming to interactive MDX\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">MDX file saved to: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">MDX_Transformed_20250520_203251/08_Understanding_Modern_ATS_Systems_What_Job_Seekers_Need_to_Know/08_Understanding_</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Modern_ATS_Systems_What_Job_Seekers_Need_to_Know.mdx</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mMDX file saved to: \u001b[0m\n",
       "\u001b[32mMDX_Transformed_20250520_203251/08_Understanding_Modern_ATS_Systems_What_Job_Seekers_Need_to_Know/08_Understanding_\u001b[0m\n",
       "\u001b[32mModern_ATS_Systems_What_Job_Seekers_Need_to_Know.mdx\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>: Analyzing transformation results<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Step \u001b[1;36m4\u001b[0m: Analyzing transformation results\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✓ Completed:</span> mvp_launch_markdown/08_Understanding_Modern_ATS_Systems_What_Job_Seekers_Need_to_Know.md -&gt; \n",
       "MDX_Transformed_20250520_203251/08_Understanding_Modern_ATS_Systems_What_Job_Seekers_Need_to_Know/08_Understanding_\n",
       "Modern_ATS_Systems_What_Job_Seekers_Need_to_Know.mdx\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m✓ Completed:\u001b[0m mvp_launch_markdown/08_Understanding_Modern_ATS_Systems_What_Job_Seekers_Need_to_Know.md -> \n",
       "MDX_Transformed_20250520_203251/08_Understanding_Modern_ATS_Systems_What_Job_Seekers_Need_to_Know/08_Understanding_\n",
       "Modern_ATS_Systems_What_Job_Seekers_Need_to_Know.mdx\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Processing:</span> mvp_launch_markdown/06_Meet_the_Team_Behind_MaryJobins_Our_Vision_and_Values.md\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;34mProcessing:\u001b[0m mvp_launch_markdown/06_Meet_the_Team_Behind_MaryJobins_Our_Vision_and_Values.md\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: Parsing markdown content<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Step \u001b[1;36m1\u001b[0m: Parsing markdown content\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Parsing markdown file: mvp_launch_markdown/06_Meet_the_Team_Behind_MaryJobins_Our_Vision_and_Values.md\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Parsing markdown file: mvp_launch_markdown/06_Meet_the_Team_Behind_MaryJobins_Our_Vision_and_Values.md\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: Analyzing content for MDX enhancement opportunities<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Step \u001b[1;36m2\u001b[0m: Analyzing content for MDX enhancement opportunities\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Using Gemini to analyze content and suggest enhancements<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Using Gemini to analyze content and suggest enhancements\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Error using Gemini for analysis: </span><span style=\"color: #808000; text-decoration-color: #808000\">'Client'</span><span style=\"color: #808000; text-decoration-color: #808000\"> object has no attribute </span><span style=\"color: #808000; text-decoration-color: #808000\">'generate_content'</span><span style=\"color: #808000; text-decoration-color: #808000\">. Using rule-based analysis </span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">instead.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mError using Gemini for analysis: \u001b[0m\u001b[33m'Client'\u001b[0m\u001b[33m object has no attribute \u001b[0m\u001b[33m'generate_content'\u001b[0m\u001b[33m. Using rule-based analysis \u001b[0m\n",
       "\u001b[33minstead.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>: Transforming to interactive MDX<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Step \u001b[1;36m3\u001b[0m: Transforming to interactive MDX\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">MDX file saved to: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">MDX_Transformed_20250520_203251/06_Meet_the_Team_Behind_MaryJobins_Our_Vision_and_Values/06_Meet_the_Team_Behind_Ma</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ryJobins_Our_Vision_and_Values.mdx</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mMDX file saved to: \u001b[0m\n",
       "\u001b[32mMDX_Transformed_20250520_203251/06_Meet_the_Team_Behind_MaryJobins_Our_Vision_and_Values/06_Meet_the_Team_Behind_Ma\u001b[0m\n",
       "\u001b[32mryJobins_Our_Vision_and_Values.mdx\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>: Analyzing transformation results<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Step \u001b[1;36m4\u001b[0m: Analyzing transformation results\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✓ Completed:</span> mvp_launch_markdown/06_Meet_the_Team_Behind_MaryJobins_Our_Vision_and_Values.md -&gt; \n",
       "MDX_Transformed_20250520_203251/06_Meet_the_Team_Behind_MaryJobins_Our_Vision_and_Values/06_Meet_the_Team_Behind_Ma\n",
       "ryJobins_Our_Vision_and_Values.mdx\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m✓ Completed:\u001b[0m mvp_launch_markdown/06_Meet_the_Team_Behind_MaryJobins_Our_Vision_and_Values.md -> \n",
       "MDX_Transformed_20250520_203251/06_Meet_the_Team_Behind_MaryJobins_Our_Vision_and_Values/06_Meet_the_Team_Behind_Ma\n",
       "ryJobins_Our_Vision_and_Values.mdx\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Processing:</span> mvp_launch_markdown/09_How_We_Use_Ollama_AI_to_Personalize_Your_Job_Matches.md\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;34mProcessing:\u001b[0m mvp_launch_markdown/09_How_We_Use_Ollama_AI_to_Personalize_Your_Job_Matches.md\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: Parsing markdown content<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Step \u001b[1;36m1\u001b[0m: Parsing markdown content\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Parsing markdown file: mvp_launch_markdown/09_How_We_Use_Ollama_AI_to_Personalize_Your_Job_Matches.md\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Parsing markdown file: mvp_launch_markdown/09_How_We_Use_Ollama_AI_to_Personalize_Your_Job_Matches.md\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: Analyzing content for MDX enhancement opportunities<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Step \u001b[1;36m2\u001b[0m: Analyzing content for MDX enhancement opportunities\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Using Gemini to analyze content and suggest enhancements<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Using Gemini to analyze content and suggest enhancements\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Error using Gemini for analysis: </span><span style=\"color: #808000; text-decoration-color: #808000\">'Client'</span><span style=\"color: #808000; text-decoration-color: #808000\"> object has no attribute </span><span style=\"color: #808000; text-decoration-color: #808000\">'generate_content'</span><span style=\"color: #808000; text-decoration-color: #808000\">. Using rule-based analysis </span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">instead.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mError using Gemini for analysis: \u001b[0m\u001b[33m'Client'\u001b[0m\u001b[33m object has no attribute \u001b[0m\u001b[33m'generate_content'\u001b[0m\u001b[33m. Using rule-based analysis \u001b[0m\n",
       "\u001b[33minstead.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>: Transforming to interactive MDX<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Step \u001b[1;36m3\u001b[0m: Transforming to interactive MDX\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">MDX file saved to: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">MDX_Transformed_20250520_203251/09_How_We_Use_Ollama_AI_to_Personalize_Your_Job_Matches/09_How_We_Use_Ollama_AI_to_</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Personalize_Your_Job_Matches.mdx</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mMDX file saved to: \u001b[0m\n",
       "\u001b[32mMDX_Transformed_20250520_203251/09_How_We_Use_Ollama_AI_to_Personalize_Your_Job_Matches/09_How_We_Use_Ollama_AI_to_\u001b[0m\n",
       "\u001b[32mPersonalize_Your_Job_Matches.mdx\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>: Analyzing transformation results<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Step \u001b[1;36m4\u001b[0m: Analyzing transformation results\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✓ Completed:</span> mvp_launch_markdown/09_How_We_Use_Ollama_AI_to_Personalize_Your_Job_Matches.md -&gt; \n",
       "MDX_Transformed_20250520_203251/09_How_We_Use_Ollama_AI_to_Personalize_Your_Job_Matches/09_How_We_Use_Ollama_AI_to_\n",
       "Personalize_Your_Job_Matches.mdx\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m✓ Completed:\u001b[0m mvp_launch_markdown/09_How_We_Use_Ollama_AI_to_Personalize_Your_Job_Matches.md -> \n",
       "MDX_Transformed_20250520_203251/09_How_We_Use_Ollama_AI_to_Personalize_Your_Job_Matches/09_How_We_Use_Ollama_AI_to_\n",
       "Personalize_Your_Job_Matches.mdx\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Processing:</span> mvp_launch_markdown/07_The_Mary_Poppins_Philosophy_Bringing_Order_to_Job_Search_Chaos.md\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;34mProcessing:\u001b[0m mvp_launch_markdown/07_The_Mary_Poppins_Philosophy_Bringing_Order_to_Job_Search_Chaos.md\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: Parsing markdown content<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Step \u001b[1;36m1\u001b[0m: Parsing markdown content\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Parsing markdown file: mvp_launch_markdown/07_The_Mary_Poppins_Philosophy_Bringing_Order_to_Job_Search_Chaos.md\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Parsing markdown file: mvp_launch_markdown/07_The_Mary_Poppins_Philosophy_Bringing_Order_to_Job_Search_Chaos.md\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: Analyzing content for MDX enhancement opportunities<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Step \u001b[1;36m2\u001b[0m: Analyzing content for MDX enhancement opportunities\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Using Gemini to analyze content and suggest enhancements<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Using Gemini to analyze content and suggest enhancements\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Error using Gemini for analysis: </span><span style=\"color: #808000; text-decoration-color: #808000\">'Client'</span><span style=\"color: #808000; text-decoration-color: #808000\"> object has no attribute </span><span style=\"color: #808000; text-decoration-color: #808000\">'generate_content'</span><span style=\"color: #808000; text-decoration-color: #808000\">. Using rule-based analysis </span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">instead.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mError using Gemini for analysis: \u001b[0m\u001b[33m'Client'\u001b[0m\u001b[33m object has no attribute \u001b[0m\u001b[33m'generate_content'\u001b[0m\u001b[33m. Using rule-based analysis \u001b[0m\n",
       "\u001b[33minstead.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>: Transforming to interactive MDX<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Step \u001b[1;36m3\u001b[0m: Transforming to interactive MDX\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">MDX file saved to: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">MDX_Transformed_20250520_203251/07_The_Mary_Poppins_Philosophy_Bringing_Order_to_Job_Search_Chaos/07_The_Mary_Poppi</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ns_Philosophy_Bringing_Order_to_Job_Search_Chaos.mdx</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mMDX file saved to: \u001b[0m\n",
       "\u001b[32mMDX_Transformed_20250520_203251/07_The_Mary_Poppins_Philosophy_Bringing_Order_to_Job_Search_Chaos/07_The_Mary_Poppi\u001b[0m\n",
       "\u001b[32mns_Philosophy_Bringing_Order_to_Job_Search_Chaos.mdx\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>: Analyzing transformation results<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Step \u001b[1;36m4\u001b[0m: Analyzing transformation results\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✓ Completed:</span> mvp_launch_markdown/07_The_Mary_Poppins_Philosophy_Bringing_Order_to_Job_Search_Chaos.md -&gt; \n",
       "MDX_Transformed_20250520_203251/07_The_Mary_Poppins_Philosophy_Bringing_Order_to_Job_Search_Chaos/07_The_Mary_Poppi\n",
       "ns_Philosophy_Bringing_Order_to_Job_Search_Chaos.mdx\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m✓ Completed:\u001b[0m mvp_launch_markdown/07_The_Mary_Poppins_Philosophy_Bringing_Order_to_Job_Search_Chaos.md -> \n",
       "MDX_Transformed_20250520_203251/07_The_Mary_Poppins_Philosophy_Bringing_Order_to_Job_Search_Chaos/07_The_Mary_Poppi\n",
       "ns_Philosophy_Bringing_Order_to_Job_Search_Chaos.mdx\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Processing:</span> mvp_launch_markdown/02_Behind_the_Magic_The_Tech_Stack_Powering_MaryJobins.md\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;34mProcessing:\u001b[0m mvp_launch_markdown/02_Behind_the_Magic_The_Tech_Stack_Powering_MaryJobins.md\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: Parsing markdown content<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Step \u001b[1;36m1\u001b[0m: Parsing markdown content\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Parsing markdown file: mvp_launch_markdown/02_Behind_the_Magic_The_Tech_Stack_Powering_MaryJobins.md\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Parsing markdown file: mvp_launch_markdown/02_Behind_the_Magic_The_Tech_Stack_Powering_MaryJobins.md\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: Analyzing content for MDX enhancement opportunities<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Step \u001b[1;36m2\u001b[0m: Analyzing content for MDX enhancement opportunities\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Using Gemini to analyze content and suggest enhancements<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Using Gemini to analyze content and suggest enhancements\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Error using Gemini for analysis: </span><span style=\"color: #808000; text-decoration-color: #808000\">'Client'</span><span style=\"color: #808000; text-decoration-color: #808000\"> object has no attribute </span><span style=\"color: #808000; text-decoration-color: #808000\">'generate_content'</span><span style=\"color: #808000; text-decoration-color: #808000\">. Using rule-based analysis </span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">instead.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mError using Gemini for analysis: \u001b[0m\u001b[33m'Client'\u001b[0m\u001b[33m object has no attribute \u001b[0m\u001b[33m'generate_content'\u001b[0m\u001b[33m. Using rule-based analysis \u001b[0m\n",
       "\u001b[33minstead.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>: Transforming to interactive MDX<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Step \u001b[1;36m3\u001b[0m: Transforming to interactive MDX\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">MDX file saved to: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">MDX_Transformed_20250520_203251/02_Behind_the_Magic_The_Tech_Stack_Powering_MaryJobins/02_Behind_the_Magic_The_Tech</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">_Stack_Powering_MaryJobins.mdx</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mMDX file saved to: \u001b[0m\n",
       "\u001b[32mMDX_Transformed_20250520_203251/02_Behind_the_Magic_The_Tech_Stack_Powering_MaryJobins/02_Behind_the_Magic_The_Tech\u001b[0m\n",
       "\u001b[32m_Stack_Powering_MaryJobins.mdx\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>: Analyzing transformation results<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Step \u001b[1;36m4\u001b[0m: Analyzing transformation results\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✓ Completed:</span> mvp_launch_markdown/02_Behind_the_Magic_The_Tech_Stack_Powering_MaryJobins.md -&gt; \n",
       "MDX_Transformed_20250520_203251/02_Behind_the_Magic_The_Tech_Stack_Powering_MaryJobins/02_Behind_the_Magic_The_Tech\n",
       "_Stack_Powering_MaryJobins.mdx\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m✓ Completed:\u001b[0m mvp_launch_markdown/02_Behind_the_Magic_The_Tech_Stack_Powering_MaryJobins.md -> \n",
       "MDX_Transformed_20250520_203251/02_Behind_the_Magic_The_Tech_Stack_Powering_MaryJobins/02_Behind_the_Magic_The_Tech\n",
       "_Stack_Powering_MaryJobins.mdx\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Transformation process completed!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32mTransformation process completed!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Processed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span> files\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Processed \u001b[1;36m9\u001b[0m files\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Successful transformations: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Successful transformations: \u001b[1;36m9\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Failed transformations: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Failed transformations: \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Summary available at: MDX_Transformed_20250520_203251/00_transformation_summary.md\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Summary available at: MDX_Transformed_20250520_203251/00_transformation_summary.md\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "======================================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "======================================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">MDX TRANSFORMATION COMPLETED\n",
       "</pre>\n"
      ],
      "text/plain": [
       "MDX TRANSFORMATION COMPLETED\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">======================================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "======================================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "Transformed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span> files\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "Transformed \u001b[1;36m9\u001b[0m of \u001b[1;36m9\u001b[0m files\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">All transformed files with detailed logs are available in: MDX_Transformed_20250520_203251\n",
       "</pre>\n"
      ],
      "text/plain": [
       "All transformed files with detailed logs are available in: MDX_Transformed_20250520_203251\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Summary file: MDX_Transformed_20250520_203251/00_transformation_summary.md\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Summary file: MDX_Transformed_20250520_203251/00_transformation_summary.md\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 8: Process Markdown Directory\n",
    "\n",
    "# Define directory to process\n",
    "MARKDOWN_DIR = \"mvp_launch_markdown\"\n",
    "\n",
    "# Check if directory exists\n",
    "if os.path.exists(MARKDOWN_DIR):\n",
    "    process_dir = input(f\"Do you want to process all files in {MARKDOWN_DIR}? (y/n): \")\n",
    "    \n",
    "    if process_dir.lower() == \"y\":\n",
    "        console.print(f\"Starting to process all files in {MARKDOWN_DIR}...\")\n",
    "        results = await process_markdown_directory(MARKDOWN_DIR)\n",
    "        \n",
    "        if results[\"status\"] == \"completed\":\n",
    "            console.print(\"\\n\" + \"=\" * 70)\n",
    "            console.print(\"MDX TRANSFORMATION COMPLETED\")\n",
    "            console.print(\"=\" * 70)\n",
    "            console.print(f\"\\nTransformed {results['successful_transformations']} of {results['files_processed']} files\")\n",
    "            console.print(f\"All transformed files with detailed logs are available in: {results['output_directory']}\")\n",
    "            console.print(f\"Summary file: {results['summary_file']}\")\n",
    "    else:\n",
    "        console.print(\"Directory processing skipped.\")\n",
    "else:\n",
    "    console.print(f\"[bold yellow]Directory {MARKDOWN_DIR} not found.[/bold yellow]\")\n",
    "    console.print(\"If you want to process files in a different directory, please provide the path.\")\n",
    "    \n",
    "    custom_dir = input(\"Enter directory path (or press Enter to skip): \")\n",
    "    \n",
    "    if custom_dir and os.path.exists(custom_dir):\n",
    "        console.print(f\"Starting to process all files in {custom_dir}...\")\n",
    "        results = await process_markdown_directory(custom_dir)\n",
    "        \n",
    "        if results[\"status\"] == \"completed\":\n",
    "            console.print(\"\\n\" + \"=\" * 70)\n",
    "            console.print(\"MDX TRANSFORMATION COMPLETED\")\n",
    "            console.print(\"=\" * 70)\n",
    "            console.print(f\"\\nTransformed {results['successful_transformations']} of {results['files_processed']} files\")\n",
    "            console.print(f\"All transformed files with detailed logs are available in: {results['output_directory']}\")\n",
    "            console.print(f\"Summary file: {results['summary_file']}\")\n",
    "    else:\n",
    "        console.print(\"No valid directory provided. Skipping directory processing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b79425-e996-4cfe-807f-e2f7c8f86dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1430347e-beaf-4b07-be7e-f67b267a0a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available attributes in agents module:\n",
      "- Agent\n",
      "- BaseAgent\n",
      "- LiveRequest\n",
      "- LiveRequestQueue\n",
      "- LlmAgent\n",
      "- LoopAgent\n",
      "- ParallelAgent\n",
      "- RunConfig\n",
      "- SequentialAgent\n",
      "- active_streaming_tool\n",
      "- base_agent\n",
      "- callback_context\n",
      "- invocation_context\n",
      "- live_request_queue\n",
      "- llm_agent\n",
      "- loop_agent\n",
      "- parallel_agent\n",
      "- readonly_context\n",
      "- run_config\n",
      "- sequential_agent\n",
      "- transcription_entry\n",
      "\n",
      "Agent constructor parameters:\n",
      "- data: Any\n",
      "\n",
      "Found models module. Available attributes:\n",
      "- BaseLlm\n",
      "- Gemini\n",
      "- LLMRegistry\n",
      "- LlmRequest\n",
      "- LlmResponse\n",
      "- base_llm\n",
      "- base_llm_connection\n",
      "- gemini_llm_connection\n",
      "- google_llm\n",
      "- lite_llm\n",
      "- llm_request\n",
      "- llm_response\n",
      "- regex\n",
      "- registry\n",
      "\n",
      "Trying to create a simple agent:\n",
      "Success creating agent with string model name!\n",
      "\n",
      "Found lite_llm. Available attributes:\n",
      "- Any\n",
      "- AsyncGenerator\n",
      "- BaseLlm\n",
      "- BaseModel\n",
      "- ChatCompletionAssistantMessage\n",
      "- ChatCompletionDeveloperMessage\n",
      "- ChatCompletionImageUrlObject\n",
      "- ChatCompletionMessageToolCall\n",
      "- ChatCompletionTextObject\n",
      "- ChatCompletionToolMessage\n",
      "- ChatCompletionUserMessage\n",
      "- ChatCompletionVideoUrlObject\n",
      "- CustomStreamWrapper\n",
      "- Dict\n",
      "- Field\n",
      "- Function\n",
      "- FunctionChunk\n",
      "- Generator\n",
      "- Iterable\n",
      "- LiteLLMClient\n",
      "- LiteLlm\n",
      "- Literal\n",
      "- LlmRequest\n",
      "- LlmResponse\n",
      "- Message\n",
      "- ModelResponse\n",
      "- OpenAIMessageContent\n",
      "- Optional\n",
      "- TYPE_LABELS\n",
      "- TextChunk\n",
      "- Tuple\n",
      "- Union\n",
      "- acompletion\n",
      "- base64\n",
      "- cast\n",
      "- completion\n",
      "- json\n",
      "- logger\n",
      "- logging\n",
      "- override\n",
      "- types\n"
     ]
    }
   ],
   "source": [
    "# Debug the ADK structure to find the correct way to specify models\n",
    "\n",
    "from google.adk import agents, runners, tools, sessions\n",
    "import inspect\n",
    "\n",
    "# Check what's available in the agents module\n",
    "print(\"Available attributes in agents module:\")\n",
    "for attr in dir(agents):\n",
    "    if not attr.startswith('_'):  # Skip private attributes\n",
    "        print(f\"- {attr}\")\n",
    "\n",
    "# Look at Agent's parameters\n",
    "print(\"\\nAgent constructor parameters:\")\n",
    "try:\n",
    "    sig = inspect.signature(agents.Agent.__init__)\n",
    "    for param_name, param in sig.parameters.items():\n",
    "        if param_name != 'self':\n",
    "            print(f\"- {param_name}: {param.annotation}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error inspecting Agent: {e}\")\n",
    "\n",
    "# Check if there's a specific module for models\n",
    "try:\n",
    "    from google.adk import models\n",
    "    print(\"\\nFound models module. Available attributes:\")\n",
    "    for attr in dir(models):\n",
    "        if not attr.startswith('_'):\n",
    "            print(f\"- {attr}\")\n",
    "except ImportError:\n",
    "    print(\"\\nNo direct 'models' module found\")\n",
    "\n",
    "# Check for example agents\n",
    "print(\"\\nTrying to create a simple agent:\")\n",
    "try:\n",
    "    # Try with a simple string model name\n",
    "    test_agent = agents.Agent(\n",
    "        name=\"test_agent\",\n",
    "        model=\"gemini-pro\",  # Try without a Model class\n",
    "        description=\"Test agent\",\n",
    "        instruction=\"Simple test\"\n",
    "    )\n",
    "    print(\"Success creating agent with string model name!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating agent with string model name: {e}\")\n",
    "\n",
    "# Try to find how to import LiteLLM if it exists\n",
    "try:\n",
    "    from google.adk.models import lite_llm\n",
    "    print(\"\\nFound lite_llm. Available attributes:\")\n",
    "    for attr in dir(lite_llm):\n",
    "        if not attr.startswith('_'):\n",
    "            print(f\"- {attr}\")\n",
    "except ImportError:\n",
    "    print(\"\\nNo lite_llm module found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "519332b4-af80-4cbc-ab3a-8dbc591d954f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created agent with string model name\n",
      "Model-related modules: ['models']\n",
      "Attempting to run the agent...\n",
      "Error running agent: 404 NOT_FOUND. {'error': {'code': 404, 'message': 'models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/qw/3z0h6fq537194cm5xh_z1gcc0000gn/T/ipykernel_25004/1533077587.py\", line 55, in try_run_agent\n",
      "    async for event in runner.run_async(\n",
      "  File \"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/google/adk/runners.py\", line 197, in run_async\n",
      "    async for event in invocation_context.agent.run_async(invocation_context):\n",
      "  File \"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/google/adk/agents/base_agent.py\", line 133, in run_async\n",
      "    async for event in self._run_async_impl(ctx):\n",
      "  File \"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/google/adk/agents/llm_agent.py\", line 246, in _run_async_impl\n",
      "    async for event in self._llm_flow.run_async(ctx):\n",
      "  File \"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 243, in run_async\n",
      "    async for event in self._run_one_step_async(invocation_context):\n",
      "  File \"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 268, in _run_one_step_async\n",
      "    async for llm_response in self._call_llm_async(\n",
      "  File \"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 483, in _call_llm_async\n",
      "    async for llm_response in llm.generate_content_async(\n",
      "  File \"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/google/adk/models/google_llm.py\", line 140, in generate_content_async\n",
      "    response = await self.api_client.aio.models.generate_content(\n",
      "  File \"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/google/genai/models.py\", line 6672, in generate_content\n",
      "    response = await self._generate_content(\n",
      "  File \"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/google/genai/models.py\", line 5674, in _generate_content\n",
      "    response_dict = await self._api_client.async_request(\n",
      "  File \"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/google/genai/_api_client.py\", line 789, in async_request\n",
      "    result = await self._async_request(http_request=http_request, stream=False)\n",
      "  File \"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/google/genai/_api_client.py\", line 733, in _async_request\n",
      "    await errors.APIError.raise_for_async_response(response)\n",
      "  File \"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/google/genai/errors.py\", line 129, in raise_for_async_response\n",
      "    raise ClientError(status_code, response_json, response)\n",
      "google.genai.errors.ClientError: 404 NOT_FOUND. {'error': {'code': 404, 'message': 'models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try different approaches to create an agent\n",
    "\n",
    "from google.adk import agents, runners, tools, sessions\n",
    "from google.genai import types\n",
    "\n",
    "# Set up session service\n",
    "session_service = sessions.InMemorySessionService()\n",
    "APP_NAME = \"test_app\"\n",
    "\n",
    "# Approach 1: Try with just a model name string\n",
    "try:\n",
    "    test_agent1 = agents.Agent(\n",
    "        name=\"test_agent1\",\n",
    "        model=\"gemini-pro\",  # Just a string\n",
    "        description=\"Test agent with string model\",\n",
    "        instruction=\"You are a simple test agent. Respond with a short confirmation message.\"\n",
    "    )\n",
    "    print(\"Created agent with string model name\")\n",
    "except Exception as e:\n",
    "    print(f\"Error with string model name: {e}\")\n",
    "\n",
    "\n",
    "# Approach 3: Look for any model-related classes in google.adk\n",
    "try:\n",
    "    # Import all modules from google.adk to inspect\n",
    "    import google.adk\n",
    "    all_modules = dir(google.adk)\n",
    "    model_related = [m for m in all_modules if 'model' in m.lower()]\n",
    "    print(f\"Model-related modules: {model_related}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error inspecting modules: {e}\")\n",
    "\n",
    "# Try to run the first agent if it was created successfully\n",
    "async def try_run_agent():\n",
    "    if 'test_agent1' in locals() or 'test_agent1' in globals():\n",
    "        test_session_id = \"test_session\"\n",
    "        session_service.create_session(\n",
    "            app_name=APP_NAME,\n",
    "            user_id=\"test_user\",\n",
    "            session_id=test_session_id\n",
    "        )\n",
    "        \n",
    "        runner = runners.Runner(\n",
    "            agent=test_agent1,\n",
    "            app_name=APP_NAME,\n",
    "            session_service=session_service\n",
    "        )\n",
    "        \n",
    "        test_message = \"Please confirm that you're working correctly.\"\n",
    "        test_content = types.Content(role='user', parts=[types.Part(text=test_message)])\n",
    "        \n",
    "        try:\n",
    "            print(\"Attempting to run the agent...\")\n",
    "            response_text = \"\"\n",
    "            async for event in runner.run_async(\n",
    "                user_id=\"test_user\",\n",
    "                session_id=test_session_id,\n",
    "                new_message=test_content\n",
    "            ):\n",
    "                if hasattr(event, 'is_final_response') and (\n",
    "                    (callable(event.is_final_response) and event.is_final_response()) or\n",
    "                    (not callable(event.is_final_response) and event.is_final_response)\n",
    "                ):\n",
    "                    if hasattr(event, 'content') and event.content and hasattr(event.content, 'parts') and event.content.parts:\n",
    "                        part = event.content.parts[0]\n",
    "                        if hasattr(part, 'text'):\n",
    "                            response_text = part.text\n",
    "            \n",
    "            print(f\"Agent response: {response_text[:100]}...\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error running agent: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return False\n",
    "    else:\n",
    "        print(\"No agent was successfully created to run\")\n",
    "        return False\n",
    "\n",
    "# Run the test\n",
    "await try_run_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad5ab8d3-acab-4e09-975c-967ab9c841c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing agent with Gemini API...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m20:16:37 - LiteLLM:ERROR\u001b[0m: vertex_llm_base.py:290 - Failed to load vertex credentials. Check to see if credentials containing partial/invalid information.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py\", line 286, in get_access_token\n",
      "    _credentials, credential_project_id = self.load_auth(\n",
      "  File \"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py\", line 95, in load_auth\n",
      "    creds, creds_project_id = google_auth.default(\n",
      "  File \"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/google/auth/_default.py\", line 685, in default\n",
      "    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)\n",
      "google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">✗ Agent test failed: litellm.APIConnectionError: Your default credentials were not found. To set up Application </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Default Credentials, see </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold; text-decoration: underline\">https://cloud.google.com/docs/authentication/external/set-up-adc</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> for more information.</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback (most recent call last):</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">  File </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">\"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/main.py\"</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">, line </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">511</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">, in </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">acompletion</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">    response = await init_response</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">  File </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">\"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_googl</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">e_ai_studio_gemini.py\"</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">, line </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">1290</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">, in async_completion</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">    _auth_header, vertex_project = await self._ensure_access_token_async(</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">  File </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">\"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py\"</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">, </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">line </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">359</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">, in _ensure_access_token_async</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">    raise e</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">  File </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">\"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py\"</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">, </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">line </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">354</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">, in _ensure_access_token_async</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">    return await asyncify(self.get_access_token)(</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">  File </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">\"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/litellm_core_utils/asyncify.py\"</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">, line </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">57</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">, in wrapper</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">    return await anyio.to_thread.run_sync(</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">  File </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">\"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/anyio/to_thread.py\"</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">, line </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">56</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">, in </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">run_sync</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">    return await get_async_backend().run_sync_in_worker_thread(</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">  File </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">\"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\"</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">, line </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">2470</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">, in run_sync_in_worker_thread</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">    return await future</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">  File </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">\"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\"</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">, line </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">967</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">,</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">in run</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">    result = context.run(func, *args)</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">  File </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">\"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py\"</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">, </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">line </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">293</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">, in get_access_token</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">    raise e</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">  File </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">\"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py\"</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">, </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">line </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">286</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">, in get_access_token</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">    _credentials, credential_project_id = self.load_auth(</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">  File </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">\"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py\"</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">, </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">line </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">95</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">, in load_auth</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">    creds, creds_project_id = google_auth.default(</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">  File </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">\"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/google/auth/_default.py\"</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">, line </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">685</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">, in </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">default</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Default Credentials, see </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold; text-decoration: underline\">https://cloud.google.com/docs/authentication/external/set-up-adc</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> for more information.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31m✗ Agent test failed: litellm.APIConnectionError: Your default credentials were not found. To set up Application \u001b[0m\n",
       "\u001b[1;31mDefault Credentials, see \u001b[0m\u001b[1;4;31mhttps://cloud.google.com/docs/authentication/external/set-up-adc\u001b[0m\u001b[1;31m for more information.\u001b[0m\n",
       "\u001b[1;31mTraceback \u001b[0m\u001b[1;31m(\u001b[0m\u001b[1;31mmost recent call last\u001b[0m\u001b[1;31m)\u001b[0m\u001b[1;31m:\u001b[0m\n",
       "\u001b[1;31m  File \u001b[0m\u001b[1;31m\"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/main.py\"\u001b[0m\u001b[1;31m, line \u001b[0m\u001b[1;31m511\u001b[0m\u001b[1;31m, in \u001b[0m\n",
       "\u001b[1;31macompletion\u001b[0m\n",
       "\u001b[1;31m    response = await init_response\u001b[0m\n",
       "\u001b[1;31m  File \u001b[0m\n",
       "\u001b[1;31m\"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_googl\u001b[0m\n",
       "\u001b[1;31me_ai_studio_gemini.py\"\u001b[0m\u001b[1;31m, line \u001b[0m\u001b[1;31m1290\u001b[0m\u001b[1;31m, in async_completion\u001b[0m\n",
       "\u001b[1;31m    _auth_header, vertex_project = await \u001b[0m\u001b[1;31mself._ensure_access_token_async\u001b[0m\u001b[1;31m(\u001b[0m\n",
       "\u001b[1;31m  File \u001b[0m\n",
       "\u001b[1;31m\"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py\"\u001b[0m\u001b[1;31m, \u001b[0m\n",
       "\u001b[1;31mline \u001b[0m\u001b[1;31m359\u001b[0m\u001b[1;31m, in _ensure_access_token_async\u001b[0m\n",
       "\u001b[1;31m    raise e\u001b[0m\n",
       "\u001b[1;31m  File \u001b[0m\n",
       "\u001b[1;31m\"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py\"\u001b[0m\u001b[1;31m, \u001b[0m\n",
       "\u001b[1;31mline \u001b[0m\u001b[1;31m354\u001b[0m\u001b[1;31m, in _ensure_access_token_async\u001b[0m\n",
       "\u001b[1;31m    return await \u001b[0m\u001b[1;31masyncify\u001b[0m\u001b[1;31m(\u001b[0m\u001b[1;31mself.get_access_token\u001b[0m\u001b[1;31m)\u001b[0m\u001b[1;31m(\u001b[0m\n",
       "\u001b[1;31m  File \u001b[0m\n",
       "\u001b[1;31m\"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/litellm_core_utils/asyncify.py\"\u001b[0m\u001b[1;31m, line \u001b[0m\n",
       "\u001b[1;31m57\u001b[0m\u001b[1;31m, in wrapper\u001b[0m\n",
       "\u001b[1;31m    return await \u001b[0m\u001b[1;31manyio.to_thread.run_sync\u001b[0m\u001b[1;31m(\u001b[0m\n",
       "\u001b[1;31m  File \u001b[0m\u001b[1;31m\"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/anyio/to_thread.py\"\u001b[0m\u001b[1;31m, line \u001b[0m\u001b[1;31m56\u001b[0m\u001b[1;31m, in \u001b[0m\n",
       "\u001b[1;31mrun_sync\u001b[0m\n",
       "\u001b[1;31m    return await \u001b[0m\u001b[1;31mget_async_backend\u001b[0m\u001b[1;31m(\u001b[0m\u001b[1;31m)\u001b[0m\u001b[1;31m.run_sync_in_worker_thread\u001b[0m\u001b[1;31m(\u001b[0m\n",
       "\u001b[1;31m  File \u001b[0m\u001b[1;31m\"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\"\u001b[0m\u001b[1;31m, line \u001b[0m\n",
       "\u001b[1;31m2470\u001b[0m\u001b[1;31m, in run_sync_in_worker_thread\u001b[0m\n",
       "\u001b[1;31m    return await future\u001b[0m\n",
       "\u001b[1;31m  File \u001b[0m\u001b[1;31m\"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\"\u001b[0m\u001b[1;31m, line \u001b[0m\u001b[1;31m967\u001b[0m\u001b[1;31m,\u001b[0m\n",
       "\u001b[1;31min run\u001b[0m\n",
       "\u001b[1;31m    result = \u001b[0m\u001b[1;31mcontext.run\u001b[0m\u001b[1;31m(\u001b[0m\u001b[1;31mfunc, *args\u001b[0m\u001b[1;31m)\u001b[0m\n",
       "\u001b[1;31m  File \u001b[0m\n",
       "\u001b[1;31m\"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py\"\u001b[0m\u001b[1;31m, \u001b[0m\n",
       "\u001b[1;31mline \u001b[0m\u001b[1;31m293\u001b[0m\u001b[1;31m, in get_access_token\u001b[0m\n",
       "\u001b[1;31m    raise e\u001b[0m\n",
       "\u001b[1;31m  File \u001b[0m\n",
       "\u001b[1;31m\"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py\"\u001b[0m\u001b[1;31m, \u001b[0m\n",
       "\u001b[1;31mline \u001b[0m\u001b[1;31m286\u001b[0m\u001b[1;31m, in get_access_token\u001b[0m\n",
       "\u001b[1;31m    _credentials, credential_project_id = \u001b[0m\u001b[1;31mself.load_auth\u001b[0m\u001b[1;31m(\u001b[0m\n",
       "\u001b[1;31m  File \u001b[0m\n",
       "\u001b[1;31m\"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py\"\u001b[0m\u001b[1;31m, \u001b[0m\n",
       "\u001b[1;31mline \u001b[0m\u001b[1;31m95\u001b[0m\u001b[1;31m, in load_auth\u001b[0m\n",
       "\u001b[1;31m    creds, creds_project_id = \u001b[0m\u001b[1;31mgoogle_auth.default\u001b[0m\u001b[1;31m(\u001b[0m\n",
       "\u001b[1;31m  File \u001b[0m\u001b[1;31m\"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/google/auth/_default.py\"\u001b[0m\u001b[1;31m, line \u001b[0m\u001b[1;31m685\u001b[0m\u001b[1;31m, in \u001b[0m\n",
       "\u001b[1;31mdefault\u001b[0m\n",
       "\u001b[1;31m    raise \u001b[0m\u001b[1;31mexceptions.DefaultCredentialsError\u001b[0m\u001b[1;31m(\u001b[0m\u001b[1;31m_CLOUD_SDK_MISSING_CREDENTIALS\u001b[0m\u001b[1;31m)\u001b[0m\n",
       "\u001b[1;31mgoogle.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application \u001b[0m\n",
       "\u001b[1;31mDefault Credentials, see \u001b[0m\u001b[1;4;31mhttps://cloud.google.com/docs/authentication/external/set-up-adc\u001b[0m\u001b[1;31m for more information.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Error details: litellm.APIConnectionError: Your default credentials were not found. To set up Application Default \n",
       "Credentials, see <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://cloud.google.com/docs/authentication/external/set-up-adc</span> for more information.\n",
       "Traceback <span style=\"font-weight: bold\">(</span>most recent call last<span style=\"font-weight: bold\">)</span>:\n",
       "  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/main.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">511</span>, in \n",
       "acompletion\n",
       "    response = await init_response\n",
       "  File \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_googl</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">e_ai_studio_gemini.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1290</span>, in async_completion\n",
       "    _auth_header, vertex_project = await <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self._ensure_access_token_async</span><span style=\"font-weight: bold\">(</span>\n",
       "  File \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py\"</span>, \n",
       "line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">359</span>, in _ensure_access_token_async\n",
       "    raise e\n",
       "  File \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py\"</span>, \n",
       "line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">354</span>, in _ensure_access_token_async\n",
       "    return await <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">asyncify</span><span style=\"font-weight: bold\">(</span>self.get_access_token<span style=\"font-weight: bold\">)(</span>\n",
       "  File \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/litellm_core_utils/asyncify.py\"</span>, line \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">57</span>, in wrapper\n",
       "    return await <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">anyio.to_thread.run_sync</span><span style=\"font-weight: bold\">(</span>\n",
       "  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/anyio/to_thread.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">56</span>, in \n",
       "run_sync\n",
       "    return await <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">get_async_backend</span><span style=\"font-weight: bold\">()</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.run_sync_in_worker_thread</span><span style=\"font-weight: bold\">(</span>\n",
       "  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\"</span>, line \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2470</span>, in run_sync_in_worker_thread\n",
       "    return await future\n",
       "  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">967</span>,\n",
       "in run\n",
       "    result = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">context.run</span><span style=\"font-weight: bold\">(</span>func, *args<span style=\"font-weight: bold\">)</span>\n",
       "  File \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py\"</span>, \n",
       "line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">293</span>, in get_access_token\n",
       "    raise e\n",
       "  File \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py\"</span>, \n",
       "line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">286</span>, in get_access_token\n",
       "    _credentials, credential_project_id = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self.load_auth</span><span style=\"font-weight: bold\">(</span>\n",
       "  File \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py\"</span>, \n",
       "line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">95</span>, in load_auth\n",
       "    creds, creds_project_id = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">google_auth.default</span><span style=\"font-weight: bold\">(</span>\n",
       "  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/google/auth/_default.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">685</span>, in \n",
       "default\n",
       "    raise <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">exceptions.DefaultCredentialsError</span><span style=\"font-weight: bold\">(</span>_CLOUD_SDK_MISSING_CREDENTIALS<span style=\"font-weight: bold\">)</span>\n",
       "google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application \n",
       "Default Credentials, see <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://cloud.google.com/docs/authentication/external/set-up-adc</span> for more information.\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Error details: litellm.APIConnectionError: Your default credentials were not found. To set up Application Default \n",
       "Credentials, see \u001b[4;94mhttps://cloud.google.com/docs/authentication/external/set-up-adc\u001b[0m for more information.\n",
       "Traceback \u001b[1m(\u001b[0mmost recent call last\u001b[1m)\u001b[0m:\n",
       "  File \u001b[32m\"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/main.py\"\u001b[0m, line \u001b[1;36m511\u001b[0m, in \n",
       "acompletion\n",
       "    response = await init_response\n",
       "  File \n",
       "\u001b[32m\"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_googl\u001b[0m\n",
       "\u001b[32me_ai_studio_gemini.py\"\u001b[0m, line \u001b[1;36m1290\u001b[0m, in async_completion\n",
       "    _auth_header, vertex_project = await \u001b[1;35mself._ensure_access_token_async\u001b[0m\u001b[1m(\u001b[0m\n",
       "  File \n",
       "\u001b[32m\"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py\"\u001b[0m, \n",
       "line \u001b[1;36m359\u001b[0m, in _ensure_access_token_async\n",
       "    raise e\n",
       "  File \n",
       "\u001b[32m\"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py\"\u001b[0m, \n",
       "line \u001b[1;36m354\u001b[0m, in _ensure_access_token_async\n",
       "    return await \u001b[1;35masyncify\u001b[0m\u001b[1m(\u001b[0mself.get_access_token\u001b[1m)\u001b[0m\u001b[1m(\u001b[0m\n",
       "  File \n",
       "\u001b[32m\"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/litellm_core_utils/asyncify.py\"\u001b[0m, line \n",
       "\u001b[1;36m57\u001b[0m, in wrapper\n",
       "    return await \u001b[1;35manyio.to_thread.run_sync\u001b[0m\u001b[1m(\u001b[0m\n",
       "  File \u001b[32m\"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/anyio/to_thread.py\"\u001b[0m, line \u001b[1;36m56\u001b[0m, in \n",
       "run_sync\n",
       "    return await \u001b[1;35mget_async_backend\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\u001b[1;35m.run_sync_in_worker_thread\u001b[0m\u001b[1m(\u001b[0m\n",
       "  File \u001b[32m\"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\"\u001b[0m, line \n",
       "\u001b[1;36m2470\u001b[0m, in run_sync_in_worker_thread\n",
       "    return await future\n",
       "  File \u001b[32m\"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\"\u001b[0m, line \u001b[1;36m967\u001b[0m,\n",
       "in run\n",
       "    result = \u001b[1;35mcontext.run\u001b[0m\u001b[1m(\u001b[0mfunc, *args\u001b[1m)\u001b[0m\n",
       "  File \n",
       "\u001b[32m\"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py\"\u001b[0m, \n",
       "line \u001b[1;36m293\u001b[0m, in get_access_token\n",
       "    raise e\n",
       "  File \n",
       "\u001b[32m\"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py\"\u001b[0m, \n",
       "line \u001b[1;36m286\u001b[0m, in get_access_token\n",
       "    _credentials, credential_project_id = \u001b[1;35mself.load_auth\u001b[0m\u001b[1m(\u001b[0m\n",
       "  File \n",
       "\u001b[32m\"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py\"\u001b[0m, \n",
       "line \u001b[1;36m95\u001b[0m, in load_auth\n",
       "    creds, creds_project_id = \u001b[1;35mgoogle_auth.default\u001b[0m\u001b[1m(\u001b[0m\n",
       "  File \u001b[32m\"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/google/auth/_default.py\"\u001b[0m, line \u001b[1;36m685\u001b[0m, in \n",
       "default\n",
       "    raise \u001b[1;35mexceptions.DefaultCredentialsError\u001b[0m\u001b[1m(\u001b[0m_CLOUD_SDK_MISSING_CREDENTIALS\u001b[1m)\u001b[0m\n",
       "google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application \n",
       "Default Credentials, see \u001b[4;94mhttps://cloud.google.com/docs/authentication/external/set-up-adc\u001b[0m for more information.\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADK and model setup working: False\n",
      "There seems to be an issue with the ADK or API key setup.\n",
      "Please check your environment configuration before proceeding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/main.py\", line 511, in acompletion\n",
      "    response = await init_response\n",
      "  File \"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py\", line 1290, in async_completion\n",
      "    _auth_header, vertex_project = await self._ensure_access_token_async(\n",
      "  File \"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py\", line 359, in _ensure_access_token_async\n",
      "    raise e\n",
      "  File \"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py\", line 354, in _ensure_access_token_async\n",
      "    return await asyncify(self.get_access_token)(\n",
      "  File \"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/litellm_core_utils/asyncify.py\", line 57, in wrapper\n",
      "    return await anyio.to_thread.run_sync(\n",
      "  File \"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py\", line 293, in get_access_token\n",
      "    raise e\n",
      "  File \"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py\", line 286, in get_access_token\n",
      "    _credentials, credential_project_id = self.load_auth(\n",
      "  File \"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py\", line 95, in load_auth\n",
      "    creds, creds_project_id = google_auth.default(\n",
      "  File \"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/google/auth/_default.py\", line 685, in default\n",
      "    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)\n",
      "google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/qw/3z0h6fq537194cm5xh_z1gcc0000gn/T/ipykernel_25004/795794246.py\", line 34, in run_test_agent\n",
      "    async for event in test_runner.run_async(\n",
      "  File \"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/google/adk/runners.py\", line 197, in run_async\n",
      "    async for event in invocation_context.agent.run_async(invocation_context):\n",
      "  File \"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/google/adk/agents/base_agent.py\", line 133, in run_async\n",
      "    async for event in self._run_async_impl(ctx):\n",
      "  File \"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/google/adk/agents/llm_agent.py\", line 246, in _run_async_impl\n",
      "    async for event in self._llm_flow.run_async(ctx):\n",
      "  File \"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 243, in run_async\n",
      "    async for event in self._run_one_step_async(invocation_context):\n",
      "  File \"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 268, in _run_one_step_async\n",
      "    async for llm_response in self._call_llm_async(\n",
      "  File \"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 483, in _call_llm_async\n",
      "    async for llm_response in llm.generate_content_async(\n",
      "  File \"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/google/adk/models/lite_llm.py\", line 675, in generate_content_async\n",
      "    response = await self.llm_client.acompletion(**completion_args)\n",
      "  File \"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/google/adk/models/lite_llm.py\", line 88, in acompletion\n",
      "    return await acompletion(\n",
      "  File \"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/utils.py\", line 1490, in wrapper_async\n",
      "    raise e\n",
      "  File \"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/utils.py\", line 1351, in wrapper_async\n",
      "    result = await original_function(*args, **kwargs)\n",
      "  File \"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/main.py\", line 530, in acompletion\n",
      "    raise exception_type(\n",
      "  File \"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2232, in exception_type\n",
      "    raise e\n",
      "  File \"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2208, in exception_type\n",
      "    raise APIConnectionError(\n",
      "litellm.exceptions.APIConnectionError: litellm.APIConnectionError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/main.py\", line 511, in acompletion\n",
      "    response = await init_response\n",
      "  File \"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py\", line 1290, in async_completion\n",
      "    _auth_header, vertex_project = await self._ensure_access_token_async(\n",
      "  File \"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py\", line 359, in _ensure_access_token_async\n",
      "    raise e\n",
      "  File \"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py\", line 354, in _ensure_access_token_async\n",
      "    return await asyncify(self.get_access_token)(\n",
      "  File \"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/litellm_core_utils/asyncify.py\", line 57, in wrapper\n",
      "    return await anyio.to_thread.run_sync(\n",
      "  File \"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py\", line 293, in get_access_token\n",
      "    raise e\n",
      "  File \"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py\", line 286, in get_access_token\n",
      "    _credentials, credential_project_id = self.load_auth(\n",
      "  File \"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py\", line 95, in load_auth\n",
      "    creds, creds_project_id = google_auth.default(\n",
      "  File \"/Users/falcon/anaconda3/envs/google-adk/lib/python3.9/site-packages/google/auth/_default.py\", line 685, in default\n",
      "    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)\n",
      "google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Simple Test for Agent and Model Setup\n",
    "\n",
    "# Create a very simple test agent\n",
    "test_agent = Agent(\n",
    "    name=\"test_agent\",\n",
    "    model=LiteLlm(MODEL_GEMINI_1_5_FLASH),  # Using the correct model name\n",
    "    description=\"Test agent to verify model setup\",\n",
    "    instruction=\"You are a simple test agent. Respond with a short confirmation message.\"\n",
    ")\n",
    "\n",
    "# Create a test session\n",
    "test_session_id = \"test_session\"\n",
    "session_service.create_session(\n",
    "    app_name=APP_NAME,\n",
    "    user_id=\"test_user\",\n",
    "    session_id=test_session_id\n",
    ")\n",
    "\n",
    "# Create a runner for the test agent\n",
    "test_runner = Runner(\n",
    "    agent=test_agent,\n",
    "    app_name=APP_NAME,\n",
    "    session_service=session_service\n",
    ")\n",
    "\n",
    "# Define a simple test function\n",
    "async def run_test_agent():\n",
    "    test_message = \"Please confirm that you're working correctly.\"\n",
    "    test_content = types.Content(role='user', parts=[types.Part(text=test_message)])\n",
    "    \n",
    "    response_text = \"\"\n",
    "    \n",
    "    try:\n",
    "        async for event in test_runner.run_async(\n",
    "            user_id=\"test_user\",\n",
    "            session_id=test_session_id,\n",
    "            new_message=test_content\n",
    "        ):\n",
    "            if hasattr(event, 'is_final_response') and (\n",
    "                (callable(event.is_final_response) and event.is_final_response()) or\n",
    "                (not callable(event.is_final_response) and event.is_final_response)\n",
    "            ):\n",
    "                if hasattr(event, 'content') and event.content and hasattr(event.content, 'parts') and event.content.parts:\n",
    "                    part = event.content.parts[0]\n",
    "                    if hasattr(part, 'text'):\n",
    "                        response_text = part.text\n",
    "        \n",
    "        console.print(f\"[bold green]✓ Agent test successful![/bold green]\")\n",
    "        console.print(f\"[bold]Response:[/bold] {response_text[:100]}...\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        console.print(f\"[bold red]✗ Agent test failed: {str(e)}[/bold red]\")\n",
    "        console.print(\"Error details:\", str(e))\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "# Run the test\n",
    "print(\"Testing agent with Gemini API...\")\n",
    "is_setup_working = await run_test_agent()\n",
    "print(f\"ADK and model setup working: {is_setup_working}\")\n",
    "\n",
    "if not is_setup_working:\n",
    "    print(\"There seems to be an issue with the ADK or API key setup.\")\n",
    "    print(\"Please check your environment configuration before proceeding.\")\n",
    "else:\n",
    "    print(\"Setup verification successful. Ready to proceed with MDX transformer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb34b775-e9b3-46c0-9490-e516706fbcd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
